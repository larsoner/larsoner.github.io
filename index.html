<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Eric Larson, ">


        <title>Eric Larson // </title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="./theme/css/pure.css">
    <link rel="stylesheet" href="./theme/css/academicons.css">


    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
</head>

<body>
<div class="pure-g-r" id="layout">
<div class="sidebar pure-u">
    <div class="cover-img" style="background: none repeat scroll 0% 0% #5f1904">
        <div class="cover-body">
            <header class="header">
            <hgroup>
                    <a href="/">
                        <img class="avatar" src="/images/profile.jpg">
                    </a>

                <nav id="nav">

                    <h2><a href="/">Eric Larson</a></h2>

                    <p class="brand-main-sub">
                        <em>Research Scientist</em>
                        <br />
                        <a href="http://ilabs.washington.edu">Institute for Learning and Brain Sciences</a>,
                        <br />
                        <a href="https://washington.edu">University of Washington</a>
                    </p>

                    <p>
                        <ul>
                            <li class="nav"><a href="index.html#shortbio" id="about-link" class="skel-layers-ignoreHref">Short Bio</a></li>
                            <li class="nav"><a href="index.html#software" id="software-link" class="skel-layers-ignoreHref">Software</a></li>
                            <li class="nav"><a href="publications.html" id="publications-link" class="skel-layers-ignoreHref">Publications</a></li>
                        </ul>
                    </p>
                </nav>

                <p class="tagline"></p>


                <p class="social">
                <a href="https://github.com/larsoner/">
                    <i class="fa fa-github fa-3x"></i>
                </a>
                <a href="https://scholar.google.com/citations?user=87KLuLUAAAAJ">
                    <i class="ai ai-google-scholar-square ai-3x"></i>
                </a>
                <a href="www.linkedin.com/in/larsoner">
                    <i class="fa fa-linkedin fa-3x"></i>
                </a>
                </p>
            </hgroup>
            </header>
        </div>
    </div>
</div>    <div class="pure-u-1">
        <div class="content">
            <!-- A wrapper for all the pages -->
            <div class="posts">
                    <h1 class="content-subhead" id="shortbio">Short Bio</h1>
                    <section class="post">
                        <p class="post-meta"><p>I am currently a research scientist at the University of Washington
<a href="http://ilabs.washington.edu">Institute for Learning and Brain Sciences</a>.</p>
<p>My work focuses on data science related primarily to magnetoencephalography (MEG)
and electroencephalography (EEG). My days are spent working on signal
processing, denoising, scientific computing, and software engineering for doing
better science.</p>
<p>Previously:</p>
<ul>
<li>BS in mathematics, physics, and philosophy from <a href="https://www.kzoo.edu/">Kalamazoo College</a> (2002)</li>
<li>MS/PhD in Biomedical Engineering from <a href="https://www.bu.edu/eng/departments/bme/">BU</a></li>
<li>Postdoc with Adrian KC lee, <a href="http://depts.washington.edu/labsn/People/Lee/lee.html">LABSN at UW</a></li>
</ul></p>
                    </section>
                    <h1 class="content-subhead" id="software">Software</h1>
                    <section class="post">
                        <p class="post-meta"><ul>
<li><a href="https://scipy.org">SciPy</a> - A core scientific Python library, including signal processing routines.</li>
<li><a href="http://vispy.org">VisPy</a> - A high performance OpenGL scientific visualization library.</li>
<li><a href="http://mne.tools/">MNE</a> - A complete package to process EEG and MEG data: forward and inverse problems, preprocessing, statistics, machine learning.</li>
<li><a href="http://pysurfer.github.io">PySurfer</a> - Brain visualization package.</li>
<li><a href="https://labsn.github.io/expyfun">expyfun</a> - High-precision audio-visual experimentation software.</li>
</ul>
<p>Multiple other contributions to other open source scientific packages.
More on my <a href="http://github.com/larsoner">Github Page</a></p></p>
                    </section>
                    <h1 class="content-subhead" id="contact">Contact</h1>
                    <section class="post">
                        <p class="post-meta"><p><strong>Email:</strong> <a href="mailto:larson.eric.d@gmail.com">larson.eric.d@gmail.com</a></p></p>
                    </section>
            </div>

            <div class="pure-g">
                    <div class="pure-u">
                         <div id="publications" class="posts" >
                            <h1 class="content-subhead">
                                Recent Publications
                            </h1>
<p class="post-meta">
    Virtanen, P., Gommers, R., Oliphant, T., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., van der Walt, S., Brett, M., Wilson, J., Millman, K., Mayorov, N., Nelson, A., Jones, E., Kern, R., <strong><em>Larson, E</em></strong>., Carey, C., Polat, İ., Feng, Y., Moore, E., VanderPlas, J., Laxalde, D., Perktold, J., Cimrman, R., Henriksen, I., Quintero, E., Harris, C., Archibald, A., Ribeiro, A., Pedregosa, F., van Mulbregt, P. and Contributors, S. (2019). <i>SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python</i>.
        
            .
        <a href="https://arxiv.org/abs/1907.10121v1">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_0">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_0_content">
            <pre>@article{virtanen_scipy_2019,
 author = {Virtanen, P., Gommers, R., Oliphant, T., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., van der Walt, S., Brett, M., Wilson, J., Millman, K., Mayorov, N., Nelson, A., Jones, E., Kern, R., <strong><em>Larson, E</em></strong>., Carey, C., Polat, İ., Feng, Y., Moore, E., VanderPlas, J., Laxalde, D., Perktold, J., Cimrman, R., Henriksen, I., Quintero, E., Harris, C., Archibald, A., Ribeiro, A., Pedregosa, F., van Mulbregt, P. and Contributors, S.},
 file = {Full Text PDF:/Users/larsoner/Library/Application Support/Zotero/Profiles/dlymswnx.default/zotero/storage/EVVMEN8A/Virtanen et al. - 2019 - SciPy 1.0--Fundamental Algorithms for Scientific C.pdf:application/pdf},
 language = {en},
 month = {July},
 title = {{SciPy} 1.0--{Fundamental} {Algorithms} for {Scientific} {Computing} in {Python}},
 url = {https://arxiv.org/abs/1907.10121v1},
 urldate = {2019-10-23},
 year = {2019}
}</pre>
        </div>
</p><p class="post-meta">
    McLaughlin, S., <strong><em>Larson, E</em></strong>. and Lee, A. (2019). <i>Neural Switch Asymmetry in Feature-Based Auditory Attention Tasks</i>.
        Journal of the Association for Research in Otolaryngology
            20: (205--215).
        <a href="https://doi.org/10.1007/s10162-018-00713-z">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_6">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_6_content">
            <pre>@article{mclaughlin_neural_2019,
 abstract = {Active listening involves dynamically switching attention between competing talkers and is essential to following conversations in everyday environments. Previous investigations in human listeners have examined the neural mechanisms that support switching auditory attention within the acoustic featural cues of pitch and auditory space. Here, we explored the cortical circuitry underlying endogenous switching of auditory attention between pitch and spatial cues necessary to discern target from masker words. Because these tasks are of unequal difficulty, we expected an asymmetry in behavioral switch costs for hard-to-easy versus easy-to-hard switches, mirroring prior evidence from vision-based cognitive task-switching paradigms. We investigated the neural correlates of this behavioral switch asymmetry and associated cognitive control operations in the present auditory paradigm. Behaviorally, we observed no switch-cost asymmetry, i.e., no performance difference for switching from the more difficult attend-pitch to the easier attend-space condition (P→S) versus switching from easy-to-hard (S→P). However, left lateral prefrontal cortex activity, correlated with improved performance, was observed during a silent gap period when listeners switched attention from P→S, relative to switching within pitch cues. No such differential activity was seen for the analogous easy-to-hard switch. We hypothesize that this neural switch asymmetry reflects proactive cognitive control mechanisms that successfully reconfigured neurally-specified task parameters and resolved competition from other such “task sets,” thereby obviating the expected behavioral switch-cost asymmetry. The neural switch activity observed was generally consistent with that seen in cognitive paradigms, suggesting that established cognitive models of attention switching may be productively applied to better understand similar processes in audition.},
 author = {McLaughlin, S., <strong><em>Larson, E</em></strong>. and Lee, A.},
 doi = {10.1007/s10162-018-00713-z},
 issn = {1438-7573},
 journal = {Journal of the Association for Research in Otolaryngology},
 keywords = {active listening, auditory attention, dorsolateral prefrontal cortex (DLPFC), EEG, MEG, neural switch asymmetry},
 language = {en},
 month = {April},
 number = {2},
 pages = {205--215},
 title = {Neural {Switch} {Asymmetry} in {Feature}-{Based} {Auditory} {Attention} {Tasks}},
 url = {https://doi.org/10.1007/s10162-018-00713-z},
 volume = {20},
 year = {2019}
}</pre>
        </div>
</p><p class="post-meta">
    <strong><em>Larson, E</em></strong>. and Taulu, S. (2018). <i>Reducing Sensor Noise in MEG and EEG Recordings Using Oversampled Temporal Projection</i>.
        IEEE Transactions on Biomedical Engineering
            65: (1002--1013).
        <a class="publi-bibtex-button" id="bibtex_1">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_1_content">
            <pre>@article{larson_reducing_2018,
 abstract = {Objective: Here, we review the theory of suppression of spatially uncorrelated, sensor-specific noise in electro- and magentoencephalography (EEG and MEG) arrays, and introduce a novel method for suppression. Our method requires only that the signals of interest are spatially oversampled, which is a reasonable assumption for many EEG and MEG systems. Methods: Our method is based on a leave-one-out procedure using overlapping temporal windows in a mathematical framework to project spatially uncorrelated noise in the temporal domain. Results: This method, termed “oversampled temporal projection” (OTP), has four advantages over existing methods. First, sparse channel-specific artifacts are suppressed while limiting mixing with other channels, whereas existing linear, time-invariant spatial operators can spread such artifacts to other channels with a spatial distribution which can be mistaken for one produced by an electrophysiological source. Second, OTP minimizes distortion of the spatial configuration of the data. During source localization (e.g., dipole fitting), many spatial methods require corresponding modification of the forward model to avoid bias, while OTP does not. Third, noise suppression factors at the sensor level are maintained during source localization, whereas bias compensation removes the denoising benefit for spatial methods that require such compensation. Fourth, OTP uses a time-window duration parameter to control the tradeoff between noise suppression and adaptation to time-varying sensor characteristics. Conclusion: OTP efficiently optimizes noise suppression performance while controlling for spatial bias of the signal of interest. Significance: This is important in applications where sensor noise significantly limits the signal-to-noise ratio, such as high-frequency brain oscillations.},
 author = {<strong><em>Larson, E</em></strong>. and Taulu, S.},
 doi = {10.1109/TBME.2017.2734641},
 issn = {0018-9294, 1558-2531},
 journal = {IEEE Transactions on Biomedical Engineering},
 keywords = {Artifact suppression, Bayes methods, Brain, Brain modeling, channel-specific artifacts, EEG recordings, Electroencephalography, interference, magentoencephalography, magnetoencephalography, medical signal processing, MEG, Multichannel measurement, Noise, Noise measurement, noise reduction, noise suppression factors, noise suppression performance, OTP minimizes distortion, outlier, oversampled temporal projection, sensor level, sensor noise reduction, sensor noise suppression, signal denoising, signal processing, signal reconstruction, signal-to-noise ratio, Source localization, spatial bias, spatial configuration, spatial distribution, spatially uncorrelated noise, spatially uncorrelated sensor-specific noise, spatial methods, temporal domain, temporal windows, time-invariant spatial operators, time-varying sensor characteristics, time-window duration parameter},
 month = {May},
 number = {5},
 pages = {1002--1013},
 title = {Reducing {Sensor} {Noise} in {MEG} and {EEG} {Recordings} {Using} {Oversampled} {Temporal} {Projection}},
 volume = {65},
 year = {2018}
}</pre>
        </div>
</p><p class="post-meta">
    Zhdanov, A., Nurminen, J. and <strong><em>Larson, E</em></strong>. (2018). <i>Helsinki VideoMEG Project: Augmenting magnetoencephalography with synchronized video recordings</i>.
        MethodsX
            5: (234--243).
        <a href="http://www.sciencedirect.com/science/article/pii/S2215016118300074">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_2">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_2_content">
            <pre>@article{zhdanov_helsinki_2018,
 abstract = {The primary goal of the Helsinki VideoMEG Project is to enable magnetoencephalography (MEG) practitioners to record and analyze the video of the subject during an MEG experiment jointly with the MEG data. The project provides: •Hardware assembly instructions and software for setting up video and audio recordings of the participant synchronized to MEG data acquisition.•Basic software tools for analyzing video and audio together with the MEG data. The resulting setup allows reliable recording of video and audio from the subject in various real-world usage scenarios. The Helsinki VideoMEG Project allowed successful establishment of video-MEG facilities in four different MEG laboratories in Finland, Sweden and the United States.},
 author = {Zhdanov, A., Nurminen, J. and <strong><em>Larson, E</em></strong>.},
 doi = {10.1016/j.mex.2018.01.002},
 file = {ScienceDirect Full Text PDF:/Users/larsoner/Library/Application Support/Zotero/Profiles/dlymswnx.default/zotero/storage/WTH9243C/Zhdanov et al. - 2018 - Helsinki VideoMEG Project Augmenting magnetoencep.pdf:application/pdf},
 issn = {2215-0161},
 journal = {MethodsX},
 keywords = {Biomagnetics, Epilepsy, magnetoencephalography, Video-magnetoencephalography (Video-MEG), Video recording},
 language = {en},
 month = {January},
 pages = {234--243},
 shorttitle = {Helsinki {VideoMEG} {Project}},
 title = {Helsinki {VideoMEG} {Project}: {Augmenting} magnetoencephalography with synchronized video recordings},
 url = {http://www.sciencedirect.com/science/article/pii/S2215016118300074},
 volume = {5},
 year = {2018}
}</pre>
        </div>
</p><p class="post-meta">
    Jas, M., <strong><em>Larson, E</em></strong>., Engemann, D., Leppäkangas, J., Taulu, S., Hämäläinen, M. and Gramfort, A. (2018). <i>A Reproducible MEG/EEG Group Study With the MNE Software: Recommendations, Quality Assessments, and Good Practices</i>.
        Frontiers in Neuroscience
            12: ().
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6088222/">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_3">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_3_content">
            <pre>@article{jas_reproducible_2018,
 abstract = {Cognitive neuroscience questions are commonly tested with experiments that involve a cohort of subjects. The cohort can consist of a handful of subjects for small studies to hundreds or thousands of subjects in open datasets. While there exist various online resources to get started with the analysis of magnetoencephalography (MEG) or electroencephalography (EEG) data, such educational materials are usually restricted to the analysis of a single subject. This is in part because data from larger group studies are harder to share, but also analyses of such data often require subject-specific decisions which are hard to document. This work presents the results obtained by the reanalysis of an open dataset from Wakeman and Henson () using the MNE software package. The analysis covers preprocessing steps, quality assurance steps, sensor space analysis of evoked responses, source localization, and statistics in both sensor and source space. Results with possible alternative strategies are presented and discussed at different stages such as the use of high-pass filtering versus baseline correction, tSSS vs. SSS, the use of a minimum norm inverse vs. LCMV beamformer, and the use of univariate or multivariate statistics. This aims to provide a comparative study of different stages of M/EEG analysis pipeline on the same dataset, with open access to all of the scripts necessary to reproduce this analysis.},
 author = {Jas, M., <strong><em>Larson, E</em></strong>., Engemann, D., Leppäkangas, J., Taulu, S., Hämäläinen, M. and Gramfort, A.},
 doi = {10.3389/fnins.2018.00530},
 file = {PubMed Central Full Text PDF:/Users/larsoner/Library/Application Support/Zotero/Profiles/dlymswnx.default/zotero/storage/Q4FSVCRM/Jas et al. - 2018 - A Reproducible MEGEEG Group Study With the MNE So.pdf:application/pdf},
 issn = {1662-4548},
 journal = {Frontiers in Neuroscience},
 month = {August},
 pmcid = {PMC6088222},
 pmid = {30127712},
 shorttitle = {A {Reproducible} {MEG}/{EEG} {Group} {Study} {With} the {MNE} {Software}},
 title = {A {Reproducible} {MEG}/{EEG} {Group} {Study} {With} the {MNE} {Software}: {Recommendations}, {Quality} {Assessments}, and {Good} {Practices}},
 url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6088222/},
 volume = {12},
 year = {2018}
}</pre>
        </div>
</p><p class="post-meta">
    Meltzoff, A., Ramírez, R., Saby, J., <strong><em>Larson, E</em></strong>., Taulu, S. and Marshall, P. (2018). <i>Infant brain responses to felt and observed touch of hands and feet: an MEG study</i>.
        Developmental Science
            21: (e12651).
        <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12651">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_4">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_4_content">
            <pre>@article{meltzoff_infant_2018,
 abstract = {There is growing interest concerning the ways in which the human body, both one's own and that of others, is represented in the developing human brain. In two experiments with 7-month-old infants, we employed advances in infant magnetoencephalography (MEG) brain imaging to address novel questions concerning body representations in early development. Experiment 1 evaluated the spatiotemporal organization of infants’ brain responses to being touched. A punctate touch to infants’ hands and feet produced significant activation in the hand and foot areas of contralateral primary somatosensory cortex as well as in other parietal and frontal areas. Experiment 2 explored infant brain responses to visually perceiving another person's hand or foot being touched. Results showed significant activation in early visual regions and also in regions thought to be involved in multisensory body and self–other processing. Furthermore, observed touch of the hand and foot activated the infant's own primary somatosensory cortex, although less consistently than felt touch. These findings shed light on aspects of early social cognition, including action imitation, which may build, at least in part, on infant neural representations that map equivalences between the bodies of self and other.},
 author = {Meltzoff, A., Ramírez, R., Saby, J., <strong><em>Larson, E</em></strong>., Taulu, S. and Marshall, P.},
 copyright = {© 2018 John Wiley \& Sons Ltd},
 doi = {10.1111/desc.12651},
 issn = {1467-7687},
 journal = {Developmental Science},
 language = {en},
 number = {5},
 pages = {e12651},
 shorttitle = {Infant brain responses to felt and observed touch of hands and feet},
 title = {Infant brain responses to felt and observed touch of hands and feet: an {MEG} study},
 url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12651},
 volume = {21},
 year = {2018}
}</pre>
        </div>
</p><p class="post-meta">
    McCloy, D., <strong><em>Larson, E</em></strong>. and Lee, A. (2018). <i>Auditory attention switching with listening difficulty: Behavioral and pupillometric measures</i>.
        The Journal of the Acoustical Society of America
            144: (2764--2771).
        <a href="https://asa.scitation.org/doi/abs/10.1121/1.5078618">[www]</a>
        <a class="publi-bibtex-button" id="bibtex_5">[BibTeX]</a>
        <div class="publi-bibtex" id="bibtex_5_content">
            <pre>@article{mccloy_auditory_2018,
 author = {McCloy, D., <strong><em>Larson, E</em></strong>. and Lee, A.},
 doi = {10.1121/1.5078618},
 issn = {0001-4966},
 journal = {The Journal of the Acoustical Society of America},
 month = {November},
 number = {5},
 pages = {2764--2771},
 shorttitle = {Auditory attention switching with listening difficulty},
 title = {Auditory attention switching with listening difficulty: {Behavioral} and pupillometric measures},
 url = {https://asa.scitation.org/doi/abs/10.1121/1.5078618},
 volume = {144},
 year = {2018}
}</pre>
        </div>
</p>                            <a href="publications.html">Full list of publications</a>
                        </div>
                    </div>
                </div>

            <!-- A wrapper for all the blog posts -->
            <div class="posts">
                <!--
                <h1 class="content-subhead">
                            Latest posts
                </h1>
<div class="pagination-wrapper content-subhead">
    <div class="pagination">
        <div class="pagination-left">
                &nbsp;
        </div>
        <span>Page 1 / 1</span>
        <div class="pagination-right">
        </div>
    </div>
</div>                -->
<footer class="footer">
    <p>
        &copy; Eric Larson &ndash;
        <!-- Built with joy. -->
        Built with <a href="https://github.com/PurePelicanTheme/pure-single">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
         - <a href="https://jpswalsh.github.io/academicons/" title="academicons">Academicons</a>
         - <a href="https://www.flaticon.com/authors/freepik" title="Freepik">Freepik</a>
    </p>
</footer>            </div>
        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });

        // Handle toggle of bibtex entries
        $( ".publi-bibtex-button" ).each(function( index ) {
            $(this).unbind('click').on('click', function () {
                $('#' + $(this).attr('id') + '_content').toggle('slide');
            });
        });
    </script>

    </script>
    <script type="text/javascript">
        var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
        document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
        try {
            var pageTracker = _gat._getTracker("UA-35793277-1");
            pageTracker._trackPageview();
            } catch(err) {}
    </script>
</body>
</html>