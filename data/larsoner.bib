@article{drew_using_2024,
	title = {Using a linear dynamic system to measure functional connectivity from {M}/{EEG}},
	volume = {21},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/ad5cc1},
	doi = {10.1088/1741-2552/ad5cc1},
	abstract = {Objective. Measures of functional connectivity (FC) can elucidate which cortical regions work together in order to complete a variety of behavioral tasks. This study’s primary objective was to expand a previously published model of measuring FC to include multiple subjects and several regions of interest. While FC has been more extensively investigated in vision and other sensorimotor tasks, it is not as well understood in audition. The secondary objective of this study was to investigate how auditory regions are functionally connected to other cortical regions when attention is directed to different distinct auditory stimuli. Approach. This study implements a linear dynamic system (LDS) to measure the structured time-lagged dependence across several cortical regions in order to estimate their FC during a dual-stream auditory attention task. Results. The model’s output shows consistent functionally connected regions across different listening conditions, indicative of an auditory attention network that engages regardless of endogenous switching of attention or different auditory cues being attended. Significance. The LDS implemented in this study implements a multivariate autoregression to infer FC across cortical regions during an auditory attention task. This study shows how a first-order autoregressive function can reliably measure functional connectivity from M/EEG data. Additionally, the study shows how auditory regions engage with the supramodal attention network outlined in the visual attention literature.},
	language = {en},
	number = {4},
	urldate = {2024-11-22},
	journal = {Journal of Neural Engineering},
	author = {Drew, Jordan and Foti, Nicholas and Nadkarni, Rahul and Larson, Eric and Fox, Emily and Lee, Adrian KC},
	month = jul,
	year = {2024},
	note = {Publisher: IOP Publishing},
	pages = {046020},
}

@article{larson_robust_2010,
	title = {A {Robust} and {Biologically} {Plausible} {Spike} {Pattern} {Recognition} {Network}},
	volume = {30},
	url = {http://www.jneurosci.org/cgi/content/abstract/30/46/15566},
	doi = {10.1523/JNEUROSCI.3672-10.2010},
	abstract = {The neural mechanisms that enable recognition of spiking patterns in the brain are currently unknown. This is especially relevant in sensory systems, in which the brain has to detect such patterns and recognize relevant stimuli by processing peripheral inputs; in particular, it is unclear how sensory systems can recognize time-varying stimuli by processing spiking activity. Because auditory stimuli are represented by time-varying fluctuations in frequency content, it is useful to consider how such stimuli can be recognized by neural processing. Previous models for sound recognition have used preprocessed or low-level auditory signals as input, but complex natural sounds such as speech are thought to be processed in auditory cortex, and brain regions involved in object recognition in general must deal with the natural variability present in spike trains. Thus, we used neural recordings to investigate how a spike pattern recognition system could deal with the intrinsic variability and diverse response properties of cortical spike trains. We propose a biologically plausible computational spike pattern recognition model that uses an excitatory chain of neurons to spatially preserve the temporal representation of the spike pattern. Using a single neural recording as input, the model can be trained using a spike-timing-dependent plasticity-based learning rule to recognize neural responses to 20 different bird songs with {\textgreater}98\% accuracy and can be stimulated to evoke reverse spike pattern playback. Although we test spike train recognition performance in an auditory task, this model can be applied to recognize sufficiently reliable spike patterns from any neuronal system.},
	number = {46},
	urldate = {2010-11-18},
	journal = {J. Neurosci.},
	author = {Larson, Eric and Perrone, Ben P. and Sen, Kamal and Billimoria, Cyrus P.},
	month = nov,
	year = {2010},
	pages = {15566--15572},
	file = {HighWire Snapshot:/Users/larsoner/Zotero/storage/CNZE7MWT/15566.html:text/html},
}

@article{larson_neuron-specific_2012,
	title = {Neuron-specific stimulus masking reveals interference in spike timing at the cortical level},
	volume = {13},
	issn = {1438-7573},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/21964794},
	doi = {10.1007/s10162-011-0292-1},
	abstract = {The auditory system is capable of robust recognition of sounds in the presence of competing maskers (e.g., other voices or background music). This capability arises despite the fact that masking stimuli can disrupt neural responses at the cortical level. Since the origins of such interference effects remain unknown, in this study, we work to identify and quantify neural interference effects that originate due to masking occurring within and outside receptive fields of neurons. We record from single and multi-unit auditory sites from field L, the auditory cortex homologue in zebra finches. We use a novel method called spike timing-based stimulus filtering that uses the measured response of each neuron to create an individualized stimulus set. In contrast to previous adaptive experimental approaches, which have typically focused on the average firing rate, this method uses the complete pattern of neural responses, including spike timing information, in the calculation of the receptive field. When we generate and present novel stimuli for each neuron that mask the regions within the receptive field, we find that the time-varying information in the neural responses is disrupted, degrading neural discrimination performance and decreasing spike timing reliability and sparseness. We also find that, while removing stimulus energy from frequency regions outside the receptive field does not significantly affect neural responses for many sites, adding a masker in these frequency regions can nonetheless have a significant impact on neural responses and discriminability without a significant change in the average firing rate. These findings suggest that maskers can interfere with neural responses by disrupting stimulus timing information with power either within or outside the receptive fields of neurons.},
	number = {1},
	urldate = {2012-07-23},
	journal = {Journal of the Association for Research in Otolaryngology: JARO},
	author = {Larson, Eric and Maddox, Ross K and Perrone, Ben P and Sen, Kamal and Billimoria, Cyrus P},
	month = feb,
	year = {2012},
	pmid = {21964794},
	keywords = {Animals, Reaction Time, Auditory Cortex, Neurons, Action Potentials, Perceptual Masking, Discrimination (Psychology), Finches, Vocalization, Animal},
	pages = {81--89},
}

@inproceedings{larson_toward_2011,
	address = {Graz, Austria},
	title = {Toward incorporating anatomical information in {BCI} designs},
	booktitle = {Proceedings of the 5th {International} {Brain}-{Computer} {Interfaces} {Conference}},
	author = {Larson, Eric and Lee, Adrian KC},
	month = sep,
	year = {2011},
}

@article{shinn-cunningham_bottom-up_2005,
	title = {Bottom-up and top-down influences on spatial unmasking},
	volume = {91},
	abstract = {The ability to detect and understand a Source of interest (a "target") in the presence of a competing Source (a "masker") is better when the Sources are spatially separated than when they are at the same location, ail effect known as "spatial unmasking". Many models account for spatial unmasking by predicting reduction of within-frequency-band masking; however, recent studies report significant spatial unmasking even when within-band "energetic masking" is minimal. The current study examines whether spatial unmasking depends on the veracity and kinds of spatial Cues present when the target and masker are similar and processed to have little spectral overlap. For the tested stimuli, traditional within-band models predict (at most) a modest amount of spatial unmasking that varies with condition. Instead, we observe large spatial unmasking effects. Moreover, after accounting for the broadband target and masker intensities at the acoustically better ear, the amount of spatial unmasking is essentially independent of the kind of spatial Cues that cause the target and masker the be perceived at different locations. Only at the lowest target-to-masker ratios (when within-band masking becomes significant) does the amount of spatial unmasking depend on the interaural phase differences in target and masker. These results emphasize that the relative overall intensities of the masker and target are critical for predicting how much perceptual interference the masker causes, even when "energetic masking" is minimal. We believe that in everyday settings, both traditional bottom-up factors and a higher- level mechanism depending on spatial perception contribute to spatial unmasking. We argue that the latter mechanism is a form of spatial attention, critical for meditating competition between similar, simultaneous Sources in everyday settings.},
	number = {6},
	journal = {Acta Acustica united with Acustica},
	author = {Shinn-Cunningham, B. and Ihlefeld, A. and Satyavarta and Larson, E.},
	month = oct,
	year = {2005},
	keywords = {ATTENTION, Perception, INFORMATIONAL MASKING, LEVEL, AUDITORY-NERVE DATA, ENERGETIC MASKING, SPEECH-IN℡LIGIBILITY, DIFFERENCES, SOUND SOURCES, 2 SIMULTANEOUS TALKERS, INDUCED INTERAURAL TIME},
	pages = {967--979},
}

@article{larson_biologically_2009,
	title = {A biologically plausible computational model for auditory object recognition},
	volume = {101},
	issn = {0022-3077},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18987124},
	doi = {10.1152/jn.90664.2008},
	abstract = {Object recognition is a task of fundamental importance for sensory systems. Although this problem has been intensively investigated in the visual system, relatively little is known about the recognition of complex auditory objects. Recent work has shown that spike trains from individual sensory neurons can be used to discriminate between and recognize stimuli. Multiple groups have developed spike similarity or dissimilarity metrics to quantify the differences between spike trains. Using a nearest-neighbor approach the spike similarity metrics can be used to classify the stimuli into groups used to evoke the spike trains. The nearest prototype spike train to the tested spike train can then be used to identify the stimulus. However, how biological circuits might perform such computations remains unclear. Elucidating this question would facilitate the experimental search for such circuits in biological systems, as well as the design of artificial circuits that can perform such computations. Here we present a biologically plausible model for discrimination inspired by a spike distance metric using a network of integrate-and-fire model neurons coupled to a decision network. We then apply this model to the birdsong system in the context of song discrimination and recognition. We show that the model circuit is effective at recognizing individual songs, based on experimental input data from field L, the avian primary auditory cortex analog. We also compare the performance and robustness of this model to two alternative models of song discrimination: a model based on coincidence detection and a model based on firing rate.},
	number = {1},
	urldate = {2009-05-06},
	journal = {Journal of Neurophysiology},
	author = {Larson, Eric and Billimoria, Cyrus P and Sen, Kamal},
	month = jan,
	year = {2009},
	pmid = {18987124},
	keywords = {Humans, Auditory Perception, Algorithms, Computer Simulation, Neurons, Discrimination (Psychology), Neural Networks (Computer), Models, Neurological, Synapses, Electrophysiology, Neurons/physiology, Auditory Perception/*physiology, *Models, Neurological, Pattern Recognition, Automated, Reproducibility of Results, Data Interpretation, Statistical, Music, Synapses/physiology, Discrimination (Psychology)/physiology, Computational Model, Zebra Finches, Recognition (Psychology), Recognition (Psychology)/*physiology, Decision Support Techniques, Field L},
	pages = {323--331},
	file = {HighWire Full Text PDF:/Users/larsoner/Zotero/storage/5XHI7JM5/Larson et al. - 2009 - A Biologically Plausible Computational Model for A.pdf:application/pdf;HighWire Snapshot:/Users/larsoner/Zotero/storage/A7CXJD9I/323.html:text/html;PubMed Snapshot:/Users/larsoner/Zotero/storage/QRJGWGN3/18987124.html:text/html},
}

@inproceedings{engemann_mind_2015,
	address = {Stanford, CA},
	title = {Mind the noise covariance when localizing brain sources with {M}/{EEG}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7270835},
	urldate = {2016-01-27},
	booktitle = {Pattern {Recognition} in {NeuroImaging} ({PRNI}), 2015 {International} {Workshop} on},
	publisher = {IEEE},
	author = {Engemann, Denis and Strohmeier, Daniel and Larson, Eric and Gramfort, Alexandre},
	year = {2015},
	pages = {9--12},
	file = {[PDF] from archives-ouvertes.fr:/Users/larsoner/Zotero/storage/RUD3WH2K/Engemann et al. - 2015 - Mind the noise covariance when localizing brain so.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/3MXNGICP/login.html:text/html},
}

@article{thorp_combined_2014,
	title = {Combined {Auditory} and {Vibrotactile} {Feedback} for {Human} {Machine}-{Interface} {Control}},
	volume = {22},
	issn = {1534-4320},
	doi = {10.1109/TNSRE.2013.2273177},
	abstract = {The purpose of this study was to determine the effect of the addition of binary vibrotactile stimulation to continuous auditory feedback (vowel synthesis) for human-machine interface (HMI) control. Sixteen healthy participants controlled facial surface electromyography to achieve 2-D targets (vowels). Eight participants used only real-time auditory feedback to locate targets whereas the other eight participants were additionally alerted to having achieved targets with confirmatory vibrotactile stimulation at the index finger. All participants trained using their assigned feedback modality (auditory alone or combined auditory and vibrotactile) over three sessions on three days and completed a fourth session on the third day using novel targets to assess generalization. Analyses of variance performed on the 1) percentage of targets reached and 2) percentage of trial time at the target revealed a main effect for feedback modality: participants using combined auditory and vibrotactile feedback performed significantly better than those using auditory feedback alone. No effect was found for session or the interaction of feedback modality and session, indicating a successful generalization to novel targets but lack of improvement over training sessions. Future research is necessary to determine the cognitive cost associated with combined auditory and vibrotactile feedback during HMI control.},
	number = {1},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Thorp, E.B. and Larson, E. and Stepp, C.E.},
	month = jan,
	year = {2014},
	keywords = {Auditory evoked potentials, Speech, Cognition, auditory, Electromyography, medical signal processing, Feedback, Computers, Human computer interaction, Biomedical engineering, 2D targets, binary vibrotactile stimulation, cognitive cost, combined auditory-vibrotactile feedback, confirmatory vibrotactile stimulation, continuous auditory feedback, controlled facial surface electromyography, Educational institutions, feedback modality, haptic interfaces, human-machine-interface control, human–machine interfaces (HMIs), index finger, medical control systems, real-time auditory feedback, Real-time systems, time 3 d, training sessions, vibrotactile, Visualization, vowel synthesis},
	pages = {62--68},
	file = {IEEE Xplore Abstract Record:/Users/larsoner/Zotero/storage/TRQV7ICJ/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/Users/larsoner/Zotero/storage/TWE6VV82/Thorp et al. - 2014 - Combined Auditory and Vibrotactile Feedback for Hu.pdf:application/pdf},
}

@article{larson_switching_2014,
	title = {Switching auditory attention using spatial and non-spatial features recruits different cortical networks},
	volume = {84},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191300997X},
	doi = {10.1016/j.neuroimage.2013.09.061},
	abstract = {Switching attention between different stimuli of interest based on particular task demands is important in many everyday settings. In audition in particular, switching attention between different speakers of interest that are talking concurrently is often necessary for effective communication. Recently, it has been shown by multiple studies that auditory selective attention suppresses the representation of unwanted streams in auditory cortical areas in favor of the target stream of interest. However, the neural processing that guides this selective attention process is not well understood. Here we investigated the cortical mechanisms involved in switching attention based on two different types of auditory features. By combining magneto- and electro-encephalography (M-EEG) with an anatomical MRI constraint, we examined the cortical dynamics involved in switching auditory attention based on either spatial or pitch features. We designed a paradigm where listeners were cued in the beginning of each trial to switch or maintain attention halfway through the presentation of concurrent target and masker streams. By allowing listeners time to switch during a gap in the continuous target and masker stimuli, we were able to isolate the mechanisms involved in endogenous, top–down attention switching. Our results show a double dissociation between the involvement of right temporoparietal junction (RTPJ) and the left inferior parietal supramarginal part (LIPSP) in tasks requiring listeners to switch attention based on space and pitch features, respectively, suggesting that switching attention based on these features involves at least partially separate processes or behavioral strategies.},
	urldate = {2014-01-21},
	journal = {NeuroImage},
	author = {Larson, Eric and Lee, Adrian K. C.},
	month = jan,
	year = {2014},
	keywords = {Electroencephalography, magnetoencephalography, spatial attention, auditory attention, pitch processing, Inferior parietal supramarginal part, Temporoparietal junction},
	pages = {681--687},
	file = {ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/CRH29KBU/Larson and Lee - 2014 - Switching auditory attention using spatial and non.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/67Q46WFU/S105381191300997X.html:text/html},
}

@article{gramfort_mne_2014,
	title = {{MNE} software for processing {MEG} and {EEG} data},
	volume = {86},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811913010501},
	doi = {10.1016/j.neuroimage.2013.10.027},
	abstract = {Magnetoencephalography and electroencephalography (M/EEG) measure the weak electromagnetic signals originating from neural currents in the brain. Using these signals to characterize and locate brain activity is a challenging task, as evidenced by several decades of methodological contributions. MNE, whose name stems from its capability to compute cortically-constrained minimum-norm current estimates from M/EEG data, is a software package that provides comprehensive analysis tools and workflows including preprocessing, source estimation, time–frequency analysis, statistical analysis, and several methods to estimate functional connectivity between distributed brain regions. The present paper gives detailed information about the MNE package and describes typical use cases while also warning about potential caveats in analysis. The MNE package is a collaborative effort of multiple institutes striving to implement and share best methods and to facilitate distribution of analysis pipelines to advance reproducibility of research. Full documentation is available at http://martinos.org/mne.},
	urldate = {2014-01-08},
	journal = {NeuroImage},
	author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Parkkonen, Lauri and Hämäläinen, Matti S.},
	month = feb,
	year = {2014},
	keywords = {Time–frequency analysis, Connectivity, Inverse problem, non-parametric statistics, Magnetoencephalography (MEG), software, electroencephalography (EEG)},
	pages = {446--460},
	file = {ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/J8U65GWC/Gramfort et al. - MNE software for processing MEG and EEG data.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/X6DS33SC/Gramfort et al. - 2014 - MNE software for processing MEG and EEG data.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/V8XGVRCH/S1053811913010501.html:text/html;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/38XK68RP/S1053811913010501.html:text/html},
}

@article{lee_using_2014,
	title = {Using neuroimaging to understand the cortical mechanisms of auditory selective attention},
	volume = {307},
	issn = {0378-5955},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595513001706},
	doi = {10.1016/j.heares.2013.06.010},
	abstract = {Abstract
Over the last four decades, a range of different neuroimaging tools have been used to study human auditory attention, spanning from classic event-related potential studies using electroencephalography to modern multimodal imaging approaches (e.g., combining anatomical information based on magnetic resonance imaging with magneto- and electroencephalography). This review begins by exploring the different strengths and limitations inherent to different neuroimaging methods, and then outlines some common behavioral paradigms that have been adopted to study auditory attention. We argue that in order to design a neuroimaging experiment that produces interpretable, unambiguous results, the experimenter must not only have a deep appreciation of the imaging technique employed, but also a sophisticated understanding of perception and behavior. Only with the proper caveats in mind can one begin to infer how the cortex supports a human in solving the “cocktail party” problem.

This article is part of a Special Issue entitled \&lt;Human Auditory Neuroimaging\&gt;.},
	urldate = {2013-12-08},
	journal = {Hearing Research},
	author = {Lee, Adrian K.C. and Larson, Eric and Maddox, Ross K. and Shinn-Cunningham, Barbara G.},
	month = jan,
	year = {2014},
	pages = {111--120},
	file = {1-s2.0-S0378595513001706-main.pdf:/Users/larsoner/Zotero/storage/BEREWSJ2/1-s2.0-S0378595513001706-main.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/KWQ85Z4I/S0378595513001706.html:text/html;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/TP43R628/S0378595513001706.html:text/html},
}

@article{mittag_auditory_2021,
	title = {Auditory deficits in infants at risk for dyslexia during a linguistic sensitive period predict future language},
	volume = {30},
	issn = {2213-1582},
	url = {https://www.sciencedirect.com/science/article/pii/S221315822100022X},
	doi = {10.1016/j.nicl.2021.102578},
	abstract = {Developmental dyslexia, a specific difficulty in learning to read and spell, has a strong hereditary component, which makes it possible to examine infants for early predictors of the condition even prior to the emergence of detectable symptoms. Using magnetoencephalography (MEG), we found smaller and shorter neural responses to simple sounds in infants at risk for dyslexia at 6 as compared to 12 months of age, a pattern that was reversed in age-matched controls. The findings indicate atypical auditory processing in at-risk infants across the sensitive period for native-language phoneme learning. This pattern was robust and localized to the same cortical areas regardless of the modeling parameters/algorithms used to estimate the current distribution underlying the measured activity. Its localization to left temporal and left frontal brain regions indicates a potential impact of atypical auditory processing on early language learning and later language skills because language functions are typically lateralized to the left hemisphere. This interpretation is supported by our further finding that atypical auditory responses in at-risk infants consistently predicted syntactic processing between 18 and 30 months and word production at 18 and 21 months of age. These results suggest a possible early marker of risk for dyslexia in at-risk infants.},
	language = {en},
	urldate = {2022-07-28},
	journal = {NeuroImage: Clinical},
	author = {Mittag, Maria and Larson, Eric and Clarke, Maggie and Taulu, Samu and Kuhl, Patricia K.},
	month = jan,
	year = {2021},
	keywords = {Auditory, Dyslexia, Infant, Marker, MEG},
	pages = {102578},
	file = {ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/CMRP5TIM/Mittag et al. - 2021 - Auditory deficits in infants at risk for dyslexia .pdf:application/pdf;ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/6RT5FD52/Mittag et al. - 2021 - Auditory deficits in infants at risk for dyslexia .pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/V8A7BZ94/S221315822100022X.html:text/html},
}

@article{mittag_reduced_2022,
	title = {Reduced {Theta} {Sampling} in {Infants} at {Risk} for {Dyslexia} across the {Sensitive} {Period} of {Native} {Phoneme} {Learning}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1660-4601},
	url = {https://www.mdpi.com/1660-4601/19/3/1180},
	doi = {10.3390/ijerph19031180},
	abstract = {Research on children and adults with developmental dyslexia—a specific difficulty in learning to read and spell—suggests that phonological deficits in dyslexia are linked to basic auditory deficits in temporal sampling. However, it remains undetermined whether such deficits are already present in infancy, especially during the sensitive period when the auditory system specializes in native phoneme perception. Because dyslexia is strongly hereditary, it is possible to examine infants for early predictors of the condition before detectable symptoms emerge. This study examines low-level auditory temporal sampling in infants at risk for dyslexia across the sensitive period of native phoneme learning. Using magnetoencephalography (MEG), we found deficient auditory sampling at theta in at-risk infants at both 6 and 12 months, indicating atypical auditory sampling at the syllabic rate in those infants across the sensitive period for native-language phoneme learning. This interpretation is supported by our additional finding that auditory sampling at theta predicted later vocabulary comprehension, nonlinguistic communication and the ability to combine words. Our results indicate a possible early marker of risk for dyslexia.},
	language = {en},
	number = {3},
	urldate = {2022-07-28},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Mittag, Maria and Larson, Eric and Taulu, Samu and Clarke, Maggie and Kuhl, Patricia K.},
	month = jan,
	year = {2022},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {auditory, dyslexia, infant, MEG, temporal sampling},
	pages = {1180},
	file = {Full Text PDF:/Users/larsoner/Zotero/storage/9XPFB5TA/Mittag et al. - 2022 - Reduced Theta Sampling in Infants at Risk for Dysl.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/EVUFPNMT/Mittag et al. - 2022 - Reduced Theta Sampling in Infants at Risk for Dysl.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/UIGLE4ZA/1180.html:text/html},
}

@article{luke_analysis_2021,
	title = {Analysis methods for measuring passive auditory {fNIRS} responses generated by a block-design paradigm},
	volume = {8},
	issn = {2329-423X, 2329-4248},
	url = {https://www.spiedigitallibrary.org/journals/neurophotonics/volume-8/issue-2/025008/Analysis-methods-for-measuring-passive-auditory-fNIRS-responses-generated-by/10.1117/1.NPh.8.2.025008.short},
	doi = {10.1117/1.NPh.8.2.025008},
	abstract = {Significance: Functional near-infrared spectroscopy (fNIRS) is an increasingly popular tool in auditory research, but the range of analysis procedures employed across studies may complicate the interpretation of data. Aim: We aim to assess the impact of different analysis procedures on the morphology, detection, and lateralization of auditory responses in fNIRS. Specifically, we determine whether averaging or generalized linear model (GLM)-based analysis generates different experimental conclusions when applied to a block-protocol design. The impact of parameter selection of GLMs on detecting auditory-evoked responses was also quantified. Approach: 17 listeners were exposed to three commonly employed auditory stimuli: noise, speech, and silence. A block design, comprising sounds of 5 s duration and 10 to 20 s silent intervals, was employed. Results: Both analysis procedures generated similar response morphologies and amplitude estimates, and both indicated that responses to speech were significantly greater than to noise or silence. Neither approach indicated a significant effect of brain hemisphere on responses to speech. Methods to correct for systemic hemodynamic responses using short channels improved detection at the individual level. Conclusions: Consistent with theoretical considerations, simulations, and other experimental domains, GLM and averaging analyses generate the same group-level experimental conclusions. We release this dataset publicly for use in future development and optimization of algorithms.},
	number = {2},
	urldate = {2021-06-04},
	journal = {Neurophotonics},
	author = {Luke, Robert and Larson, Eric D. and Shader, Maureen J. and Innes-Brown, Hamish and Yper, Lindsey Van and Lee, Adrian K. C. and Sowman, Paul F. and McAlpine, David},
	month = may,
	year = {2021},
	note = {Publisher: International Society for Optics and Photonics},
	pages = {025008},
	file = {Full Text PDF:/Users/larsoner/Zotero/storage/WSPW8KWU/Luke et al. - 2021 - Analysis methods for measuring passive auditory fN.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/MMQABRXW/1.NPh.8.2.025008.html:text/html},
}

@article{bosseler_using_2021,
	title = {Using magnetoencephalography to examine word recognition, lateralization, and future language skills in 14-month-old infants},
	volume = {47},
	issn = {1878-9293},
	url = {https://www.sciencedirect.com/science/article/pii/S187892932030150X},
	doi = {10.1016/j.dcn.2020.100901},
	abstract = {Word learning is a significant milestone in language acquisition. The second year of life marks a period of dramatic advances in infants’ expressive and receptive word-processing abilities. Studies show that in adulthood, language processing is left-hemisphere dominant. However, adults learning a second language activate right-hemisphere brain functions. In infancy, acquisition of a first language involves recruitment of bilateral brain networks, and strong left-hemisphere dominance emerges by the third year. In the current study we focus on 14-month-old infants in the earliest stages of word learning using infant magnetoencephalography (MEG) brain imagining to characterize neural activity in response to familiar and unfamiliar words. Specifically, we examine the relationship between right-hemisphere brain responses and prospective measures of vocabulary growth. As expected, MEG source modeling revealed a broadly distributed network in frontal, temporal and parietal cortex that distinguished word classes between 150–900 ms after word onset. Importantly, brain activity in the right frontal cortex in response to familiar words was highly correlated with vocabulary growth at 18, 21, 24, and 27 months. Specifically, higher activation to familiar words in the 150–300 ms interval was associated with faster vocabulary growth, reflecting processing efficiency, whereas higher activation to familiar words in the 600–900 ms interval was associated with slower vocabulary growth, reflecting cognitive effort. These findings inform research and theory on the involvement of right frontal cortex in specific cognitive processes and individual differences related to attention that may play an important role in the development of left-lateralized word processing.},
	language = {en},
	urldate = {2021-06-04},
	journal = {Developmental Cognitive Neuroscience},
	author = {Bosseler, Alexis N. and Clarke, Maggie and Tavabi, Kambiz and Larson, Eric D. and Hippe, Daniel S. and Taulu, Samu and Kuhl, Patricia K.},
	month = feb,
	year = {2021},
	keywords = {Attention, Infants, Language, Magnetoencephalography, Right hemisphere},
	pages = {100901},
	file = {ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/SC3JIGRS/Bosseler et al. - 2021 - Using magnetoencephalography to examine word recog.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/QZNPLGJ3/S187892932030150X.html:text/html},
}

@article{virtanen_scipy_2020,
	title = {{SciPy} 1.0: fundamental algorithms for scientific computing in {Python}},
	volume = {17},
	copyright = {2020 The Author(s)},
	issn = {1548-7105},
	shorttitle = {{SciPy} 1.0},
	url = {https://www.nature.com/articles/s41592-019-0686-2},
	doi = {10.1038/s41592-019-0686-2},
	abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
	language = {en},
	number = {3},
	urldate = {2021-05-28},
	journal = {Nature Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul},
	month = mar,
	year = {2020},
	note = {Number: 3
Publisher: Nature Publishing Group},
	pages = {261--272},
	file = {Full Text PDF:/Users/larsoner/Zotero/storage/G9N8JB77/Virtanen et al. - 2020 - SciPy 1.0 fundamental algorithms for scientific c.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/6CTTELM8/Virtanen et al. - 2020 - SciPy 1.0 fundamental algorithms for scientific c.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/IVWJKB2S/s41592-019-0686-2.html:text/html;Snapshot:/Users/larsoner/Zotero/storage/GTMSYPUY/s41592-019-0686-2.html:text/html},
}

@article{appelhoff_mne-bids_2019,
	title = {{MNE}-{BIDS}: {Organizing} electrophysiological data into the {BIDS} format and facilitating their analysis},
	volume = {4},
	issn = {2475-9066},
	shorttitle = {{MNE}-{BIDS}},
	url = {https://joss.theoj.org/papers/10.21105/joss.01896},
	doi = {10.21105/joss.01896},
	abstract = {Appelhoff et al., (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software, 4(44), 1896, https://doi.org/10.21105/joss.01896},
	language = {en},
	number = {44},
	urldate = {2021-05-28},
	journal = {Journal of Open Source Software},
	author = {Appelhoff, Stefan and Sanderson, Matthew and Brooks, Teon L. and Vliet, Marijn van and Quentin, Romain and Holdgraf, Chris and Chaumon, Maximilien and Mikulan, Ezequiel and Tavabi, Kambiz and Höchenberger, Richard and Welke, Dominik and Brunner, Clemens and Rockhill, Alexander P. and Larson, Eric and Gramfort, Alexandre and Jas, Mainak},
	month = dec,
	year = {2019},
	pages = {1896},
	file = {Full Text PDF:/Users/larsoner/Zotero/storage/RQSTQAD4/Appelhoff et al. - 2019 - MNE-BIDS Organizing electrophysiological data int.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/65DFVH5V/joss.html:text/html},
}

@article{oreilly_structural_2021,
	title = {Structural templates for imaging {EEG} cortical sources in infants},
	volume = {227},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920311678},
	doi = {10.1016/j.neuroimage.2020.117682},
	abstract = {Electroencephalographic (EEG) source reconstruction is a powerful approach that allows anatomical localization of electrophysiological brain activity. Algorithms used to estimate cortical sources require an anatomical model of the head and the brain, generally reconstructed using magnetic resonance imaging (MRI). When such scans are unavailable, a population average can be used for adults, but no average surface template is available for cortical source imaging in infants. To address this issue, we introduce a new series of 13 anatomical models for subjects between zero and 24 months of age. These templates are built from MRI averages and boundary element method (BEM) segmentation of head tissues available as part of the Neurodevelopmental MRI Database. Surfaces separating the pia mater, the gray matter, and the white matter were estimated using the Infant FreeSurfer pipeline. The surface of the skin as well as the outer and inner skull surfaces were extracted using a cube marching algorithm followed by Laplacian smoothing and mesh decimation. We post-processed these meshes to correct topological errors and ensure watertight meshes. Source reconstruction with these templates is demonstrated and validated using 100 high-density EEG recordings from 7-month-old infants. Hopefully, these templates will support future studies on EEG-based neuroimaging and functional connectivity in healthy infants as well as in clinical pediatric populations.},
	language = {en},
	urldate = {2021-01-12},
	journal = {NeuroImage},
	author = {O'Reilly, Christian and Larson, Eric and Richards, John E. and Elsabbagh, Mayada},
	month = feb,
	year = {2021},
	keywords = {Electroencephalography, Forward model, Infant, Neurodevelopment, Population template, Source reconstruction},
	pages = {117682},
	file = {ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/7USHTBRG/O'Reilly et al. - 2021 - Structural templates for imaging EEG cortical sour.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/ECX2XMZA/S1053811920311678.html:text/html},
}

@article{clarke_effectively_2020,
	title = {Effectively combining temporal projection noise suppression methods in magnetoencephalography},
	issn = {0165-0270},
	url = {http://www.sciencedirect.com/science/article/pii/S0165027020301230},
	doi = {10.1016/j.jneumeth.2020.108700},
	abstract = {Background
Magnetoencephalography (MEG) is an excellent non-invasive tool to study the brain. However, measurements often suffer from the contribution of external interference, including noise from the sensors. Suppression of noise from the data is critical for an accurate representation of brain signals. Due to MEG’s limited spatial resolution and superior temporal resolution, noise suppression methods that operate in the temporal domain can be favorable.
New Method
We examined the independent and joint effects of two temporal projection noise suppression algorithms for MEG measurements: One commonly used algorithm which suppresses correlated noise; temporal signal space separation (tSSS) and one new method which suppresses uncorrelated sensor noise; oversampled temporal projection (OTP).
Results
We found that both OTP and tSSS effectively suppress noise in raw MEG data and have the greatest effect of joint operation in cases where SNR is low, or when detecting higher SNR single-trial responses from raw data. We additionally demonstrate how the combination of OTP and tSSS is useful for the detectability of high-frequency brain oscillations (HFO).
Comparison with existing Methods
Although the mathematical description of OTP has been described before (Larson \& Taulu, 2017), OTP’s effect on HFOs in MEG data is novel. Additionally, the combination of OTP and commonly used temporal noise suppression algorithms (i.e., tSSS) has not been shown.
Conclusions
This finding is applicable to clinical populations such as epilepsy, where HFO signals are thought to be important markers for areas of seizure onset and are typically difficult to detect with non-invasive neuroimaging methods.},
	journal = {Journal of Neuroscience Methods},
	author = {Clarke, Maggie and Larson, Eric and Tavabi, Kambiz and Taulu, Samu},
	month = may,
	year = {2020},
	keywords = {Artifact suppression, HFO, magnetoencephalography, sensor noise suppression, temporal projection},
	pages = {108700},
	file = {ScienceDirect Full Text PDF:/Users/larsoner/Zotero/storage/HBUI5ZA5/Clarke et al. - 2020 - Effectively combining temporal projection noise su.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/KDDDJ8BW/S0165027020301230.html:text/html},
}

@article{larson_reducing_2018,
	title = {Reducing {Sensor} {Noise} in {MEG} and {EEG} {Recordings} {Using} {Oversampled} {Temporal} {Projection}},
	volume = {65},
	issn = {0018-9294},
	doi = {10.1109/TBME.2017.2734641},
	abstract = {Objective: Here, we review the theory of suppression of spatially uncorrelated, sensor-specific noise in electro- and magentoencephalography (EEG and MEG) arrays, and introduce a novel method for suppression. Our method requires only that the signals of interest are spatially oversampled, which is a reasonable assumption for many EEG and MEG systems. Methods: Our method is based on a leave-one-out procedure using overlapping temporal windows in a mathematical framework to project spatially uncorrelated noise in the temporal domain. Results: This method, termed “oversampled temporal projection” (OTP), has four advantages over existing methods. First, sparse channel-specific artifacts are suppressed while limiting mixing with other channels, whereas existing linear, time-invariant spatial operators can spread such artifacts to other channels with a spatial distribution which can be mistaken for one produced by an electrophysiological source. Second, OTP minimizes distortion of the spatial configuration of the data. During source localization (e.g., dipole fitting), many spatial methods require corresponding modification of the forward model to avoid bias, while OTP does not. Third, noise suppression factors at the sensor level are maintained during source localization, whereas bias compensation removes the denoising benefit for spatial methods that require such compensation. Fourth, OTP uses a time-window duration parameter to control the tradeoff between noise suppression and adaptation to time-varying sensor characteristics. Conclusion: OTP efficiently optimizes noise suppression performance while controlling for spatial bias of the signal of interest. Significance: This is important in applications where sensor noise significantly limits the signal-to-noise ratio, such as high-frequency brain oscillations.},
	number = {5},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Larson, E. and Taulu, S.},
	month = may,
	year = {2018},
	keywords = {Artifact suppression, Brain modeling, Electroencephalography, interference, magnetoencephalography, Multichannel measurement, Noise measurement, noise reduction, outlier, sensor noise suppression, signal processing},
	pages = {1002--1013},
	file = {IEEE Xplore Abstract Record:/Users/larsoner/Zotero/storage/6MHRWD4U/7997929.html:text/html;IEEE Xplore Abstract Record:/Users/larsoner/Zotero/storage/WAK8WKDJ/7997929.html:text/html;IEEE Xplore Abstract Record:/Users/larsoner/Zotero/storage/G5QWH52E/7997929.html:text/html},
}

@article{larson_categorical_2013,
	title = {Categorical {Vowel} {Perception} {Enhances} the {Effectiveness} and {Generalization} of {Auditory} {Feedback} in {Human}-{Machine}-{Interfaces}},
	volume = {8},
	url = {http://dx.doi.org/10.1371/journal.pone.0059860},
	doi = {10.1371/journal.pone.0059860},
	abstract = {Human-machine interface (HMI) designs offer the possibility of improving quality of life for patient populations as well as augmenting normal user function. Despite pragmatic benefits, utilizing auditory feedback for HMI control remains underutilized, in part due to observed limitations in effectiveness. The goal of this study was to determine the extent to which categorical speech perception could be used to improve an auditory HMI. Using surface electromyography, 24 healthy speakers of American English participated in 4 sessions to learn to control an HMI using auditory feedback (provided via vowel synthesis). Participants trained on 3 targets in sessions 1–3 and were tested on 3 novel targets in session 4. An “established categories with text cues” group of eight participants were trained and tested on auditory targets corresponding to standard American English vowels using auditory and text target cues. An “established categories without text cues” group of eight participants were trained and tested on the same targets using only auditory cuing of target vowel identity. A “new categories” group of eight participants were trained and tested on targets that corresponded to vowel-like sounds not part of American English. Analyses of user performance revealed significant effects of session and group (established categories groups and the new categories group), and a trend for an interaction between session and group. Results suggest that auditory feedback can be effectively used for HMI operation when paired with established categorical (native vowel) targets with an unambiguous cue.},
	number = {3},
	urldate = {2013-05-28},
	journal = {PLoS ONE},
	author = {Larson, Eric and Terry, Howard P. and Canevari, Margaux M. and Stepp, Cara E.},
	month = mar,
	year = {2013},
	pages = {e59860},
	file = {PLoS Full Text PDF:/Users/larsoner/Zotero/storage/5A73VNZ9/Larson et al. - 2013 - Categorical Vowel Perception Enhances the Effectiv.pdf:application/pdf;PLoS Snapshot:/Users/larsoner/Zotero/storage/4J7FNNUV/infodoi10.1371journal.pone.html:text/html},
}

@article{butera_functional_2022,
	title = {Functional localization of audiovisual speech using near infrared spectroscopy},
	volume = {35},
	issn = {1573-6792},
	url = {https://doi.org/10.1007/s10548-022-00904-1},
	doi = {10.1007/s10548-022-00904-1},
	abstract = {Visual cues are especially vital for hearing impaired individuals such as cochlear implant (CI) users to understand speech in noise. Functional Near Infrared Spectroscopy (fNIRS) is a light-based imaging technology that is ideally suited for measuring the brain activity of CI users due to its compatibility with both the ferromagnetic and electrical components of these implants. In a preliminary step toward better elucidating the behavioral and neural correlates of audiovisual (AV) speech integration in CI users, we designed a speech-in-noise task and measured the extent to which 24 normal hearing individuals could integrate the audio of spoken monosyllabic words with the corresponding visual signals of a female speaker. In our behavioral task, we found that audiovisual pairings provided average improvements of 103\% and 197\% over auditory-alone listening conditions in −6 and −9 dB signal-to-noise ratios consisting of multi-talker background noise. In an fNIRS task using similar stimuli, we measured activity during auditory-only listening, visual-only lipreading, and AV listening conditions. We identified cortical activity in all three conditions over regions of middle and superior temporal cortex typically associated with speech processing and audiovisual integration. In addition, three channels active during the lipreading condition showed uncorrected correlations associated with behavioral measures of audiovisual gain as well as with the McGurk effect. Further work focusing primarily on the regions of interest identified in this study could test how AV speech integration may differ for CI users who rely on this mechanism for daily communication.},
	language = {en},
	number = {4},
	urldate = {2022-09-09},
	journal = {Brain Topography},
	author = {Butera, Iliza M. and Larson, Eric D. and DeFreese, Andrea J. and Lee, Adrian KC and Gifford, René H. and Wallace, Mark T.},
	month = jul,
	year = {2022},
	keywords = {Multisensory integration, fNIRS, Infrared spectroscopy, McGurk effect, Speech in noise},
	pages = {416--430},
	file = {Full Text PDF:/Users/larsoner/Zotero/storage/A4GSAUCM/Butera et al. - 2022 - Functional localization of audiovisual speech usin.pdf:application/pdf},
}

@article{hands_effects_2014,
	title = {Effects of augmentative visual training on audio-motor mapping},
	volume = {35},
	issn = {0167-9457},
	url = {https://www.sciencedirect.com/science/article/pii/S0167945714000049},
	doi = {10.1016/j.humov.2014.01.003},
	abstract = {The purpose of this study was to determine the effect of augmentative visual feedback training on auditory–motor performance. Thirty-two healthy young participants used facial surface electromyography (sEMG) to control a human–machine interface (HMI) for which the output was vowel synthesis. An auditory-only (AO) group (n=16) trained with auditory feedback alone and an auditory–visual (AV) group (n=16) trained with auditory feedback and progressively-removed visual feedback. Subjects participated in three training sessions and one testing session over 3days. During the testing session they were given novel targets to test auditory–motor generalization. We hypothesized that the auditory–visual group would perform better on the novel set of targets than the group that trained with auditory feedback only. Analysis of variance on the percentage of total targets reached indicated a significant interaction between group and session: individuals in the AV group performed significantly better than those in the AO group during early training sessions (while using visual feedback), but no difference was seen between the two groups during later sessions. Results suggest that augmentative visual feedback during training does not improve auditory–motor performance.},
	language = {en},
	urldate = {2022-09-09},
	journal = {Human Movement Science},
	author = {Hands, Gabrielle L. and Larson, Eric and Stepp, Cara E.},
	month = jun,
	year = {2014},
	keywords = {Auditory–motor, Surface electromyography, Visual feedback},
	pages = {145--155},
	file = {Accepted Version:/Users/larsoner/Zotero/storage/RZZYYW57/Hands et al. - 2014 - Effects of augmentative visual training on audio-m.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/U53WXK8X/S0167945714000049.html:text/html},
}

@article{helle_extended_2021,
	title = {Extended {Signal}-{Space} {Separation} {Method} for {Improved} {Interference} {Suppression} in {MEG}},
	volume = {68},
	issn = {1558-2531},
	doi = {10.1109/TBME.2020.3040373},
	abstract = {Objective: Magnetoencephalography (MEG) signals typically reflect a mixture of neuromagnetic fields, subject-related artifacts, external interference and sensor noise. Even inside a magnetically shielded room, external interference can be significantly stronger than brain signals. Methods such as signal-space projection (SSP) and signal-space separation (SSS) have been developed to suppress this residual interference, but their performance might not be sufficient in cases of strong interference or when the sources of interference change over time. Methods: Here we suggest a new method, extended signal-space separation (eSSS), which combines a physical model of the magnetic fields (as in SSS) with a statistical description of the interference (as in SSP). We demonstrate the performance of this method via simulations and experimental MEG data. Results: The eSSS method clearly outperforms SSS and SSP in interference suppression regardless of the extent of a priori information available on the interference sources. We also show that the method does not cause location or amplitude bias in dipole modeling. Conclusion: Our eSSS method provides better data quality than SSP or SSS and can be readily combined with other SSS-based methods, such as spatiotemporal SSS or head movement compensation. Thus, eSSS extends and complements the interference suppression techniques currently available for MEG. Significance: Due to its ability to suppress external interference to the level of sensor noise, eSSS can facilitate single-trial data analysis, exemplified in automated analysis of epileptic data. Such an enhanced suppression is especially important in environments with large interference fields.},
	number = {7},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Helle, Liisa and Nenonen, Jukka and Larson, Eric and Simola, Juha and Parkkonen, Lauri and Taulu, Samu},
	month = jul,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Calibration, External interference, interference suppression, Interference suppression, Magnetic noise, Magnetic sensors, Magnetic separation, Magnetic shielding, magnetoencephalography, principal component analysis, Sensor arrays, signal processing, signal-space separation, Signal-Space Separation},
	pages = {2211--2221},
	file = {IEEE Xplore Abstract Record:/Users/larsoner/Zotero/storage/C45Q3KHP/9268467.html:text/html;IEEE Xplore Full Text PDF:/Users/larsoner/Zotero/storage/KVQ9GN5R/Helle et al. - 2020 - Extended Signal-Space Separation method for improv.pdf:application/pdf;IEEE Xplore Full Text PDF:/Users/larsoner/Zotero/storage/TDZDDEAT/Helle et al. - 2021 - Extended Signal-Space Separation Method for Improv.pdf:application/pdf},
}

@article{yeo_effects_2023,
	title = {Effects of head modeling errors on the spatial frequency representation of {MEG}},
	volume = {68},
	issn = {0031-9155},
	url = {https://dx.doi.org/10.1088/1361-6560/accc06},
	doi = {10.1088/1361-6560/accc06},
	abstract = {Objectives. We aim to investigate the effects of head model inaccuracies on signal and source reconstruction accuracies for various sensor array distances to the head. This allows for the assessment of the importance of head modeling for next-generation magnetoencephalography (MEG) sensors, optically-pumped magnetometers (OPM). Approach. A 1-shell boundary element method (BEM) spherical head model with 642 vertices of radius 9 cm and conductivity of 0.33 S m−1 was defined. The vertices were then randomly perturbed radially up to 2\%, 4\%, 6\%, 8\% and 10\% of the radius. For each head perturbation case, the forward signal was calculated for dipolar sources located at 2 cm, 4 cm, 6 cm and 8 cm from the origin (center of the sphere), and for a 324 sensor array located at 10 cm to 15 cm from the origin. Equivalent current dipole (ECD) source localization was performed for each of these forward signals. The signal for each perturbed spherical head case was then analyzed in the spatial frequency domain, and the signal and ECD errors were quantified relative to the unperturbed case. Main results. In the noiseless and high signal-to-noise ratio (SNR) case of approximately ≥6 dB, inaccuracies in our spherical BEM head conductor models lead to increased signal and ECD inaccuracies when sensor arrays are placed closer to the head. This is true especially in the case of deep and superficial sources. In the noisy case however, the higher SNR for closer sensor arrays allows for an improved ECD fit and outweighs the effects of head geometry inaccuracies. Significance. OPMs may be placed directly on the head, as opposed to the more commonly used superconducting quantum interference device sensors which must be placed a few centimeters away from the head. OPMs thus allow for signals of higher spatial resolution to be captured, resulting in potentially more accurate source localizations. Our results suggest that an increased emphasis on accurate head modeling for OPMs may be necessary to fully realize its improved source localization potential.},
	language = {en},
	number = {9},
	urldate = {2023-05-12},
	journal = {Physics in Medicine \& Biology},
	author = {Yeo, Wan-Jin and Larson, Eric and Iivanainen, Joonas and Borna, Amir and McKay, Jim and Stephen, Julia M. and Schwindt, Peter D. D. and Taulu, Samu},
	month = apr,
	year = {2023},
	note = {Publisher: IOP Publishing},
	pages = {095022},
	file = {IOP Full Text PDF:/Users/larsoner/Zotero/storage/LEYZEZG5/Yeo et al. - 2023 - Effects of head modeling errors on the spatial fre.pdf:application/pdf},
}

@article{sheffield_sound_2023,
	title = {Sound {Level} {Changes} the {Auditory} {Cortical} {Activation} {Detected} with {Functional} {Near}-{Infrared} {Spectroscopy}},
	volume = {36},
	issn = {1573-6792},
	url = {https://doi.org/10.1007/s10548-023-00981-w},
	doi = {10.1007/s10548-023-00981-w},
	abstract = {Functional near-infrared spectroscopy (fNIRS) is a viable non-invasive technique for functional neuroimaging in the cochlear implant (CI) population; however, the effects of acoustic stimulus features on the fNIRS signal have not been thoroughly examined. This study examined the effect of stimulus level on fNIRS responses in adults with normal hearing or bilateral CIs. We hypothesized that fNIRS responses would correlate with both stimulus level and subjective loudness ratings, but that the correlation would be weaker with CIs due to the compression of acoustic input to electric output.},
	language = {en},
	number = {5},
	urldate = {2024-04-08},
	journal = {Brain Topography},
	author = {Sheffield, Sterling W. and Larson, Eric and Butera, Iliza M. and DeFreese, Andrea and Rogers, Baxter P. and Wallace, Mark T. and Stecker, G. Christopher and Lee, Adrian K. C. and Gifford, Rene H.},
	month = sep,
	year = {2023},
	keywords = {Functional near-infrared spectroscopy, Cochlear implants, Loudness ratings, Stimulus level},
	pages = {686--697},
}

@article{bosseler_infants_2024,
	title = {Infants’ brain responses to social interaction predict future language growth},
	volume = {0},
	issn = {0960-9822},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(24)00317-8},
	doi = {10.1016/j.cub.2024.03.020},
	language = {English},
	number = {0},
	urldate = {2024-04-08},
	journal = {Current Biology},
	author = {Bosseler, Alexis N. and Meltzoff, Andrew N. and Bierer, Steven and Huber, Elizabeth and Mizrahi, Julia C. and Larson, Eric and Endevelt-Shapira, Yaara and Taulu, Samu and Kuhl, Patricia K.},
	month = apr,
	year = {2024},
	note = {Publisher: Elsevier},
	keywords = {magnetoencephalography, MEG, social interaction, behavior, infant, attention, brain, language development, neuroscience, theta oscillations},
	file = {Full Text PDF:/Users/larsoner/Zotero/storage/VAV9IDZ3/Bosseler et al. - 2024 - Infants’ brain responses to social interaction pre.pdf:application/pdf},
}

@article{yeatman_reading_2024,
	title = {Reading instruction causes changes in category-selective visual cortex},
	issn = {0361-9230},
	url = {https://www.sciencedirect.com/science/article/pii/S0361923024000911},
	doi = {10.1016/j.brainresbull.2024.110958},
	abstract = {Education sculpts specialized neural circuits for skills like reading that are critical to success in modern society but were not anticipated by the selective pressures of evolution. Does the emergence of brain regions that selectively process novel visual stimuli like words occur at the expense of cortical representations of other stimuli like faces and objects? “Neuronal Recycling” predicts that learning to read should enhance the response to words in ventral occipitotemporal cortex (VOTC) and decrease the response to other visual categories such as faces and objects. To test this hypothesis, and more broadly to understand the changes that are induced by the early stages of literacy instruction, we conducted a randomized controlled trial with pre-school children (five years of age). Children were randomly assigned to intervention programs focused on either reading skills or oral language skills and magnetoencephalography (MEG) data collected before and after the intervention was used to measure visual responses to images of text, faces, and objects. We found that being taught reading versus oral language skills induced different patterns of change in category-selective regions of visual cortex, but that there was not a clear tradeoff between the response to words versus other categories. Within a predefined region of VOTC corresponding to the visual word form area (VWFA) we found that the relative amplitude of responses to text, faces, and objects changed, but increases in the response to words were not linked to decreases in the response to faces or objects. How these changes play out over a longer timescale is still unknown but, based on these data, we can surmise that high-level visual cortex undergoes rapid changes as children enter school and begin establishing new skills like literacy.},
	urldate = {2024-05-01},
	journal = {Brain Research Bulletin},
	author = {Yeatman, Jason D. and McCloy, Daniel R. and Caffarra, Sendy and Clarke, Maggie D. and Ender, Suzanne and Gijbels, Liesbeth and Joo, Sung Jun and Kubota, Emily C. and Kuhl, Patricia K. and Larson, Eric and O’Brien, Gabrielle and Peterson, Erica R. and Takada, Megumi E. and Taulu, Samu},
	month = apr,
	year = {2024},
	keywords = {plasticity, category-selective, high-level visual cortex, neuronal recycling, reading, visual word form area (VWFA)},
	pages = {110958},
	file = {ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/UA7KMZAW/S0361923024000911.html:text/html},
}

@article{rockhill_intracranial_2022,
	title = {Intracranial {Electrode} {Location} and {Analysis} in {MNE}-{Python}},
	volume = {7},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.03897},
	doi = {10.21105/joss.03897},
	abstract = {Rockhill et al., (2022). Intracranial Electrode Location and Analysis in MNE-Python. Journal of Open Source Software, 7(70), 3897, https://doi.org/10.21105/joss.03897},
	language = {en},
	number = {70},
	urldate = {2024-05-30},
	journal = {Journal of Open Source Software},
	author = {Rockhill, Alexander P. and Larson, Eric and Stedelin, Brittany and Mantovani, Alessandra and Raslan, Ahmed M. and Gramfort, Alexandre and Swann, Nicole C.},
	month = feb,
	year = {2022},
	pages = {3897},
	file = {Full Text PDF:/Users/larsoner/Zotero/storage/4RG7IV4Q/Rockhill et al. - 2022 - Intracranial Electrode Location and Analysis in MN.pdf:application/pdf},
}

@article{mclaughlin_neural_2019,
	title = {Neural {Switch} {Asymmetry} in {Feature}-{Based} {Auditory} {Attention} {Tasks}},
	volume = {20},
	issn = {1438-7573},
	doi = {10.1007/s10162-018-00713-z},
	abstract = {Active listening involves dynamically switching attention between competing talkers and is essential to following conversations in everyday environments. Previous investigations in human listeners have examined the neural mechanisms that support switching auditory attention within the acoustic featural cues of pitch and auditory space. Here, we explored the cortical circuitry underlying endogenous switching of auditory attention between pitch and spatial cues necessary to discern target from masker words. Because these tasks are of unequal difficulty, we expected an asymmetry in behavioral switch costs for hard-to-easy versus easy-to-hard switches, mirroring prior evidence from vision-based cognitive task-switching paradigms. We investigated the neural correlates of this behavioral switch asymmetry and associated cognitive control operations in the present auditory paradigm. Behaviorally, we observed no switch-cost asymmetry, i.e., no performance difference for switching from the more difficult attend-pitch to the easier attend-space condition (P→S) versus switching from easy-to-hard (S→P). However, left lateral prefrontal cortex activity, correlated with improved performance, was observed during a silent gap period when listeners switched attention from P→S, relative to switching within pitch cues. No such differential activity was seen for the analogous easy-to-hard switch. We hypothesize that this neural switch asymmetry reflects proactive cognitive control mechanisms that successfully reconfigured neurally-specified task parameters and resolved competition from other such "task sets," thereby obviating the expected behavioral switch-cost asymmetry. The neural switch activity observed was generally consistent with that seen in cognitive paradigms, suggesting that established cognitive models of attention switching may be productively applied to better understand similar processes in audition.},
	language = {eng},
	number = {2},
	journal = {Journal of the Association for Research in Otolaryngology: JARO},
	author = {McLaughlin, Susan A. and Larson, Eric and Lee, Adrian K. C.},
	month = apr,
	year = {2019},
	pmid = {30675674},
	pmcid = {PMC6453991},
	keywords = {active listening, Adult, Attention, auditory attention, Auditory Cortex, dorsolateral prefrontal cortex (DLPFC), EEG, Female, Healthy Volunteers, Humans, Male, MEG, Middle Aged, neural switch asymmetry, Pitch Perception, Sound Localization, Young Adult},
	pages = {205--215},
	file = {Full Text:/Users/larsoner/Zotero/storage/7NKX7GUG/McLaughlin et al. - 2019 - Neural Switch Asymmetry in Feature-Based Auditory .pdf:application/pdf},
}

@article{zhdanov_helsinki_2018,
	title = {Helsinki {VideoMEG} {Project}: {Augmenting} magnetoencephalography with synchronized video recordings},
	volume = {5},
	issn = {2215-0161},
	shorttitle = {Helsinki {VideoMEG} {Project}},
	doi = {10.1016/j.mex.2018.01.002},
	abstract = {The primary goal of the Helsinki VideoMEG Project is to enable magnetoencephalography (MEG) practitioners to record and analyze the video of the subject during an MEG experiment jointly with the MEG data. The project provides: •Hardware assembly instructions and software for setting up video and audio recordings of the participant synchronized to MEG data acquisition.•Basic software tools for analyzing video and audio together with the MEG data. The resulting setup allows reliable recording of video and audio from the subject in various real-world usage scenarios. The Helsinki VideoMEG Project allowed successful establishment of video-MEG facilities in four different MEG laboratories in Finland, Sweden and the United States.},
	language = {eng},
	journal = {MethodsX},
	author = {Zhdanov, Andrey and Nurminen, Jussi and Larson, Eric},
	year = {2018},
	pmid = {30009137},
	pmcid = {PMC6043671},
	keywords = {Biomagnetics, Epilepsy, Magnetoencephalography, Video recording, Video-magnetoencephalography (Video-MEG)},
	pages = {234--243},
	file = {Full Text:/Users/larsoner/Zotero/storage/LNYQU9NF/Zhdanov et al. - 2018 - Helsinki VideoMEG Project Augmenting magnetoencep.pdf:application/pdf},
}

@article{meltzoff_infant_2018,
	title = {Infant brain responses to felt and observed touch of hands and feet: an {MEG} study},
	volume = {21},
	issn = {1467-7687},
	shorttitle = {Infant brain responses to felt and observed touch of hands and feet},
	doi = {10.1111/desc.12651},
	abstract = {There is growing interest concerning the ways in which the human body, both one's own and that of others, is represented in the developing human brain. In two experiments with 7-month-old infants, we employed advances in infant magnetoencephalography (MEG) brain imaging to address novel questions concerning body representations in early development. Experiment 1 evaluated the spatiotemporal organization of infants' brain responses to being touched. A punctate touch to infants' hands and feet produced significant activation in the hand and foot areas of contralateral primary somatosensory cortex as well as in other parietal and frontal areas. Experiment 2 explored infant brain responses to visually perceiving another person's hand or foot being touched. Results showed significant activation in early visual regions and also in regions thought to be involved in multisensory body and self-other processing. Furthermore, observed touch of the hand and foot activated the infant's own primary somatosensory cortex, although less consistently than felt touch. These findings shed light on aspects of early social cognition, including action imitation, which may build, at least in part, on infant neural representations that map equivalences between the bodies of self and other.},
	language = {eng},
	number = {5},
	journal = {Developmental Science},
	author = {Meltzoff, Andrew N. and Ramírez, Rey R. and Saby, Joni N. and Larson, Eric and Taulu, Samu and Marshall, Peter J.},
	month = sep,
	year = {2018},
	pmid = {29333688},
	pmcid = {PMC6045975},
	keywords = {Brain Mapping, Emotions, Female, Foot, Hand, Humans, Infant, Magnetoencephalography, Male, Somatosensory Cortex, Touch, Touch Perception, Visual Perception},
	pages = {e12651},
	file = {Accepted Version:/Users/larsoner/Zotero/storage/SL6P8RL8/Meltzoff et al. - 2018 - Infant brain responses to felt and observed touch .pdf:application/pdf},
}

@article{mccloy_auditory_2018,
	title = {Auditory attention switching with listening difficulty: {Behavioral} and pupillometric measures},
	volume = {144},
	issn = {1520-8524},
	shorttitle = {Auditory attention switching with listening difficulty},
	doi = {10.1121/1.5078618},
	abstract = {Pupillometry has emerged as a useful tool for studying listening effort. Past work involving listeners with normal audiological thresholds has shown that switching attention between competing talker streams evokes pupil dilation indicative of listening effort [McCloy, Lau, Larson, Pratt, and Lee (2017). J. Acoust. Soc. Am. 141(4), 2440-2451]. The current experiment examines behavioral and pupillometric data from a two-stream target detection task requiring attention-switching between auditory streams, in two participant groups: audiometrically normal listeners who self-report difficulty localizing sound sources and/or understanding speech in reverberant or acoustically crowded environments, and their age-matched controls who do not report such problems. Three experimental conditions varied the number and type of stream segregation cues available. Participants who reported listening difficulty showed both behavioral and pupillometric signs of increased effort compared to controls, especially in trials where listeners had to switch attention between streams, or trials where only a single stream segregation cue was available.},
	language = {eng},
	number = {5},
	journal = {The Journal of the Acoustical Society of America},
	author = {McCloy, Daniel R. and Larson, Eric and Lee, Adrian K. C.},
	month = nov,
	year = {2018},
	pmid = {30522295},
	pmcid = {PMC6232045},
	keywords = {Acoustic Stimulation, Adult, Aged, Attention, Auditory Perception, Auditory Threshold, Behavior Observation Techniques, Female, Humans, Male, Middle Aged, Pupil, Reaction Time, Self Report, Sound, Speech Perception},
	pages = {2764},
	file = {Full Text:/Users/larsoner/Zotero/storage/FI2EBIQ2/McCloy et al. - 2018 - Auditory attention switching with listening diffic.pdf:application/pdf},
}

@book{king_encoding_2018,
	title = {Encoding and {Decoding} {Neuronal} {Dynamics}: {Methodological} {Framework} to {Uncover} the {Algorithms} of {Cognition}},
	author = {King, Jean-Rémi and Gwilliams, Laura and Holdgraf, Chris and Sassenhagen, Jona and Barachant, Alexandre and Engemann, Denis and Larson, Eric and Gramfort, Alexandre},
	month = jan,
	year = {2018},
}

@article{mccloy_pupillometry_2017,
	title = {Pupillometry shows the effort of auditory attention switching},
	volume = {141},
	issn = {1520-8524},
	doi = {10.1121/1.4979340},
	abstract = {Successful speech communication often requires selective attention to a target stream amidst competing sounds, as well as the ability to switch attention among multiple interlocutors. However, auditory attention switching negatively affects both target detection accuracy and reaction time, suggesting that attention switches carry a cognitive cost. Pupillometry is one method of assessing mental effort or cognitive load. Two experiments were conducted to determine whether the effort associated with attention switches is detectable in the pupillary response. In both experiments, pupil dilation, target detection sensitivity, and reaction time were measured; the task required listeners to either maintain or switch attention between two concurrent speech streams. Secondary manipulations explored whether switch-related effort would increase when auditory streaming was harder. In experiment 1, spatially distinct stimuli were degraded by simulating reverberation (compromising across-time streaming cues), and target-masker talker gender match was also varied. In experiment 2, diotic streams separable by talker voice quality and pitch were degraded by noise vocoding, and the time alloted for mid-trial attention switching was varied. All trial manipulations had some effect on target detection sensitivity and/or reaction time; however, only the attention-switching manipulation affected the pupillary response: greater dilation was observed in trials requiring switching attention between talkers.},
	language = {eng},
	number = {4},
	journal = {The Journal of the Acoustical Society of America},
	author = {McCloy, Daniel R. and Lau, Bonnie K. and Larson, Eric and Pratt, Katherine A. I. and Lee, Adrian K. C.},
	month = apr,
	year = {2017},
	pmid = {28464660},
	pmcid = {PMC5848839},
	keywords = {Acoustic Stimulation, Adult, Attention, Audiometry, Speech, Auditory Threshold, Cognition, Cues, Diagnostic Techniques, Neurological, Female, Humans, Male, Noise, Perceptual Masking, Pitch Perception, Predictive Value of Tests, Pupil, Reaction Time, Speech Acoustics, Speech Perception, Time Factors, Vibration, Voice Quality, Young Adult},
	pages = {2440},
	file = {Full Text:/Users/larsoner/Zotero/storage/G6UYMJKV/McCloy et al. - 2017 - Pupillometry shows the effort of auditory attentio.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/4ZV3V3TZ/1.html:text/html;Snapshot:/Users/larsoner/Zotero/storage/79TTNURJ/1.html:text/html},
}

@article{larson_importance_2017,
	title = {The {Importance} of {Properly} {Compensating} for {Head} {Movements} {During} {MEG} {Acquisition} {Across} {Different} {Age} {Groups}},
	volume = {30},
	issn = {1573-6792},
	url = {https://doi.org/10.1007/s10548-016-0523-1},
	doi = {10.1007/s10548-016-0523-1},
	abstract = {Unlike EEG sensors, which are attached to the head, MEG sensors are located outside the head surface on a fixed external device. Subject head movements during acquisition thus distort the magnetic field distributions measured by the sensors. Previous studies have looked at the effect of head movements, but no study has comprehensively looked at the effect of head movements across age groups, particularly in infants. Using MEG recordings from subjects ranging in age from 3 months through adults, here we first quantify the variability in head position as a function of age group. We then combine these measured head movements with brain activity simulations to determine how head movements bias source localization from sensor magnetic fields measured during movement. We find that large amounts of head movement, especially common in infant age groups, can result in large localization errors. We then show that proper application of head movement compensation techniques can restore localization accuracy to pre-movement levels. We also find that proper noise covariance estimation (e.g., during the baseline period) is important to minimize localization bias following head movement compensation. Our findings suggest that head position measurement during acquisition and compensation during analysis is recommended for researchers working with subject populations or age groups that could have substantial head movements. This is especially important in infant MEG studies.},
	language = {en},
	number = {2},
	urldate = {2024-06-02},
	journal = {Brain Topography},
	author = {Larson, Eric and Taulu, Samu},
	month = mar,
	year = {2017},
	keywords = {Artifact correction, Brain development, Head movement, Magnetoencephalography, Movement compensation, Signal space separation},
	pages = {172--181},
	file = {Larson_BrainTopo_2016.pdf:/Users/larsoner/Zotero/storage/ZCRSU3FV/Larson_BrainTopo_2016.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/DVI8BQEK/10.html:text/html;Snapshot:/Users/larsoner/Zotero/storage/TC6E5JD3/s10548-016-0523-1.html:text/html},
}

@article{wronkiewicz_incorporating_2016,
	title = {Incorporating modern neuroscience findings to improve brain–computer interfaces: tracking auditory attention},
	volume = {13},
	issn = {1741-2552},
	shorttitle = {Incorporating modern neuroscience findings to improve brain–computer interfaces},
	url = {https://dx.doi.org/10.1088/1741-2560/13/5/056017},
	doi = {10.1088/1741-2560/13/5/056017},
	abstract = {Objective. Brain–computer interface (BCI) technology allows users to generate actions based solely on their brain signals. However, current non-invasive BCIs generally classify brain activity recorded from surface electroencephalography (EEG) electrodes, which can hinder the application of findings from modern neuroscience research. Approach. In this study, we use source imaging—a neuroimaging technique that projects EEG signals onto the surface of the brain—in a BCI classification framework. This allowed us to incorporate prior research from functional neuroimaging to target activity from a cortical region involved in auditory attention. Main results. Classifiers trained to detect attention switches performed better with source imaging projections than with EEG sensor signals. Within source imaging, including subject-specific anatomical MRI information (instead of using a generic head model) further improved classification performance. This source-based strategy also reduced accuracy variability across three dimensionality reduction techniques—a major design choice in most BCIs. Significance. Our work shows that source imaging provides clear quantitative and qualitative advantages to BCIs and highlights the value of incorporating modern neuroscience knowledge and methods into BCI systems.},
	language = {en},
	number = {5},
	urldate = {2024-06-02},
	journal = {Journal of Neural Engineering},
	author = {Wronkiewicz, Mark and Larson, Eric and Lee, Adrian KC},
	month = sep,
	year = {2016},
	note = {Publisher: IOP Publishing},
	pages = {056017},
	file = {jne_13_5_056017.pdf:/Users/larsoner/Zotero/storage/K97JSDN6/jne_13_5_056017.pdf:application/pdf},
}

@article{mccloy_temporal_2016,
	title = {Temporal alignment of pupillary response with stimulus events via deconvolution},
	volume = {139},
	issn = {1520-8524},
	doi = {10.1121/1.4943787},
	abstract = {Analysis of pupil dilation has been used as an index of attentional effort in the auditory domain. Previous work has modeled the pupillary response to attentional effort as a linear time-invariant system with a characteristic impulse response, and used deconvolution to estimate the attentional effort that gives rise to changes in pupil size. Here it is argued that one parameter of the impulse response (the latency of response maximum, t(max)) has been mis-estimated in the literature; a different estimate is presented, and it is shown how deconvolution with this value of t(max) yields more intuitively plausible and informative results.},
	language = {eng},
	number = {3},
	journal = {The Journal of the Acoustical Society of America},
	author = {McCloy, Daniel R. and Larson, Eric D. and Lau, Bonnie and Lee, Adrian K. C.},
	month = mar,
	year = {2016},
	pmid = {27036288},
	pmcid = {PMC5392052},
	keywords = {Acoustic noise measurement, Acoustic Stimulation, Adult, Attention, Audiometry, Auditory Perception, Deconvolution, Female, Humans, Male, Models, Theoretical, Photic Stimulation, Pupil, Reaction Time, Signal Detection, Psychological, Sound pressure, Time Factors, Time measurement, Time series analysis, Young Adult},
	pages = {EL57--62},
	file = {Full Text:/Users/larsoner/Zotero/storage/NV8MBA4B/McCloy et al. - 2016 - Temporal alignment of pupillary response with stim.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/ZJEW2RFW/McCloy et al. - 2016 - Temporal alignment of pupillary response with stim.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/8I2ENHRQ/1.html:text/html},
}

@article{larson_improving_2014,
	title = {Improving spatial localization in {MEG} inverse imaging by leveraging intersubject anatomical differences},
	volume = {8},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2014.00330/full},
	doi = {10.3389/fnins.2014.00330},
	abstract = {{\textless}p{\textgreater}Modern neuroimaging techniques enable non-invasive observation of ongoing neural processing, with magnetoencephalography (MEG) in particular providing direct measurement of neural activity with millisecond time resolution. However, accurately mapping measured MEG sensor readings onto the underlying source neural structures remains an active area of research. This so-called “inverse problem” is ill posed, and poses a challenge for source estimation that is often cited as a drawback limiting MEG data interpretation. However, anatomically constrained MEG localization estimates may be more accurate than commonly believed. Here we hypothesize that, by combining anatomically constrained inverse estimates across subjects, the spatial uncertainty of MEG source localization can be mitigated. Specifically, we argue that differences in subject brain geometry yield differences in point-spread functions, resulting in improved spatial localization across subjects. To test this, we use standard methods to combine subject anatomical MRI scans with coregistration information to obtain an accurate forward (physical) solution, modeling the MEG sensor data resulting from brain activity originating from different cortical locations. Using a linear minimum-norm inverse to localize this brain activity, we demonstrate that a substantial increase in the spatial accuracy of MEG source localization can result from combining data from subjects with differing brain geometry. This improvement may be enabled by an increase in the amount of available spatial information in MEG data as measurements from different subjects are combined. This approach becomes more important in the face of practical issues of coregistration errors and potential noise sources, where we observe even larger improvements in localization when combining data across subjects. Finally, we use a simple auditory N100(m) localization task to show how this effect can influence localization using a recorded neural dataset.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-06-02},
	journal = {Frontiers in Neuroscience},
	author = {Larson, Eric and Maddox, Ross K. and Lee, Adrian K. C.},
	month = oct,
	year = {2014},
	note = {Publisher: Frontiers},
	keywords = {Electroencephalography, inverse imaging, inverse problem, magnetoencephalography, Magnetoencephalography, minimum norm estimate (MNE), source localization, Source localization},
	file = {Full Text:/Users/larsoner/Zotero/storage/2IMW6GUQ/Larson et al. - 2014 - Improving spatial localization in MEG inverse imag.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/W8APMF25/Larson et al. - 2014 - Improving spatial localization in MEG inverse imag.pdf:application/pdf},
}

@article{lee_mapping_2012,
	title = {Mapping cortical dynamics using simultaneous {MEG}/{EEG} and anatomically-constrained minimum-norm estimates: an auditory attention example},
	issn = {1940-087X},
	shorttitle = {Mapping cortical dynamics using simultaneous {MEG}/{EEG} and anatomically-constrained minimum-norm estimates},
	doi = {10.3791/4262},
	abstract = {Magneto- and electroencephalography (MEG/EEG) are neuroimaging techniques that provide a high temporal resolution particularly suitable to investigate the cortical networks involved in dynamical perceptual and cognitive tasks, such as attending to different sounds in a cocktail party. Many past studies have employed data recorded at the sensor level only, i.e., the magnetic fields or the electric potentials recorded outside and on the scalp, and have usually focused on activity that is time-locked to the stimulus presentation. This type of event-related field / potential analysis is particularly useful when there are only a small number of distinct dipolar patterns that can be isolated and identified in space and time. Alternatively, by utilizing anatomical information, these distinct field patterns can be localized as current sources on the cortex. However, for a more sustained response that may not be time-locked to a specific stimulus (e.g., in preparation for listening to one of the two simultaneously presented spoken digits based on the cued auditory feature) or may be distributed across multiple spatial locations unknown a priori, the recruitment of a distributed cortical network may not be adequately captured by using a limited number of focal sources. Here, we describe a procedure that employs individual anatomical MRI data to establish a relationship between the sensor information and the dipole activation on the cortex through the use of minimum-norm estimates (MNE). This inverse imaging approach provides us a tool for distributed source analysis. For illustrative purposes, we will describe all procedures using FreeSurfer and MNE software, both freely available. We will summarize the MRI sequences and analysis steps required to produce a forward model that enables us to relate the expected field pattern caused by the dipoles distributed on the cortex onto the M/EEG sensors. Next, we will step through the necessary processes that facilitate us in denoising the sensor data from environmental and physiological contaminants. We will then outline the procedure for combining and mapping MEG/EEG sensor data onto the cortical space, thereby producing a family of time-series of cortical dipole activation on the brain surface (or "brain movies") related to each experimental condition. Finally, we will highlight a few statistical techniques that enable us to make scientific inference across a subject population (i.e., perform group-level analysis) based on a common cortical coordinate space.},
	language = {eng},
	number = {68},
	journal = {Journal of Visualized Experiments: JoVE},
	author = {Lee, Adrian K. C. and Larson, Eric and Maddox, Ross K.},
	month = oct,
	year = {2012},
	pmid = {23128363},
	pmcid = {PMC3490313},
	keywords = {Attention, Brain Mapping, Cerebral Cortex, Electroencephalography, Evoked Potentials, Auditory, Humans, Magnetic Resonance Imaging, magnetoencephalography, Magnetoencephalography, Monte Carlo Method},
	pages = {e4262},
	file = {Full Text:/Users/larsoner/Zotero/storage/X2SEDH3J/Lee et al. - 2012 - Mapping cortical dynamics using simultaneous MEGE.pdf:application/pdf},
}

@article{taulu_unified_2021,
	title = {Unified {Expression} of the {Quasi}-{Static} {Electromagnetic} {Field}: {Demonstration} {With} {MEG} and {EEG} {Signals}},
	volume = {68},
	issn = {1558-2531},
	shorttitle = {Unified {Expression} of the {Quasi}-{Static} {Electromagnetic} {Field}},
	url = {https://ieeexplore.ieee.org/document/9140322},
	doi = {10.1109/TBME.2020.3009053},
	abstract = {Objective: Electromagnetic recordings are useful for non-invasive measurement of human brain activity. They typically sample electric potentials on the scalp or the magnetic field outside the head using electroencephalography (EEG) or magnetoencephalography (MEG), respectively. EEG and MEG are not, however, symmetric counterparts: EEG samples a scalar field via a line integral over the electric field between two points, while MEG samples projections of a vector-valued field by small sensors. Here we present a unified mathematical formalism for electromagnetic measurements, leading to useful interpretations and signal processing methods for EEG and MEG. Methods: We represent electric and magnetic fields as solutions of Laplace's equation under the quasi-static approximation, each field representable as an expansion of the same vector spherical harmonics (VSH) but differently weighted by electro- and magnetostatic multipole moments, respectively. Results: We observe that the electric and the magnetic fields are mathematically symmetric but couple to the underlying electric source distribution in distinct ways via their corresponding multipole moments, which have concise mathematical forms. The VSH model also allows us to construct linear bases for MEG and EEG for signal processing and analysis, including interference suppression methods and system calibration. Conclusion: The VSH model is a powerful and simple approach for modeling quasi-static electromagnetic fields. Significance: Our formalism provides a unified framework for interpreting resolution questions, and paves the way for new processing and analysis methods.},
	number = {3},
	urldate = {2024-06-02},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Taulu, Samu and Larson, Eric},
	month = mar,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Biomedical Engineering},
	keywords = {Brain modeling, Conductivity, Electric potential, Electric variables measurement, electroencephalography, Electroencephalography, Magnetic recording, Magnetoencephalography, Mathematical model, non-invasive brain imaging, quasi-static approximation, vector spherical harmonics},
	pages = {992--1004},
	file = {IEEE Xplore Abstract Record:/Users/larsoner/Zotero/storage/BIGE54FX/9140322.html:text/html;IEEE Xplore Full Text PDF:/Users/larsoner/Zotero/storage/GRKI9LCU/Taulu and Larson - 2020 - Unified expression of the quasi-static electromagn.pdf:application/pdf;IEEE Xplore Full Text PDF:/Users/larsoner/Zotero/storage/4U5CEHU7/Taulu and Larson - 2021 - Unified Expression of the Quasi-Static Electromagn.pdf:application/pdf},
}

@article{emmons_auditory_2022,
	title = {Auditory {Attention} {Deployment} in {Young} {Adults} with {Autism} {Spectrum} {Disorder}},
	volume = {52},
	issn = {1573-3432},
	url = {https://doi.org/10.1007/s10803-021-05076-8},
	doi = {10.1007/s10803-021-05076-8},
	abstract = {Difficulty listening in noisy environments is a common complaint of individuals with autism spectrum disorder (ASD). However, the mechanisms underlying such auditory processing challenges are unknown. This preliminary study investigated auditory attention deployment in adults with ASD. Participants were instructed to maintain or switch attention between two simultaneous speech streams in three conditions: location (co-located versus ± 30° separation), voice (same voice versus male–female contrast), and both cues together. Results showed that individuals with ASD can selectively direct attention using location or voice cues, but performance was best when both cues were present. In comparison to neurotypical adults, overall performance was less accurate across all conditions. These findings warrant further investigation into auditory attention deployment differences in individuals with ASD.},
	language = {en},
	number = {4},
	urldate = {2024-06-03},
	journal = {Journal of Autism and Developmental Disorders},
	author = {Emmons, Katherine A. and KC Lee, Adrian and Estes, Annette and Dager, Stephen and Larson, Eric and McCloy, Daniel R. and St. John, Tanya and Lau, Bonnie K.},
	month = apr,
	year = {2022},
	keywords = {Attention, Auditory attention, Auditory Perception, Auditory processing, Autism spectrum disorder, Autism Spectrum Disorder, Female, Humans, Male, Selective attention, Speech, Speech perception, Voice, Young Adult},
	pages = {1752--1761},
	file = {Accepted Version:/Users/larsoner/Zotero/storage/RPDJTDHQ/Emmons et al. - 2022 - Auditory Attention Deployment in Young Adults with.pdf:application/pdf},
}

@article{larson_cortical_2013,
	title = {The cortical dynamics underlying effective switching of auditory spatial attention},
	volume = {64},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811912009007},
	doi = {10.1016/j.neuroimage.2012.09.006},
	abstract = {Successful rapid deployment of attention to relevant sensory stimuli is critical for survival. In a complex environment, attention can be captured by salient events or be deployed volitionally. Furthermore, when multiple events are of interest concurrently, effective interaction with one's surroundings hinges on efficient top-down control of shifting attention. It has been hypothesized that two separate cortical networks coordinate attention shifts across multiple modalities. However, the cortical dynamics of these networks and their behavioral relevance to switching of auditory attention are unknown. Here we show that the strength of each subject's right temporoparietal junction (RTPJ, part of the ventral network) activation was highly correlated with their behavioral performance in an auditory task. We also provide evidence that the recruitment of the RTPJ likely precedes the right frontal eye fields (FEF; participating in both the dorsal and ventral networks) and middle frontal gyrus (MFG) by around 100ms when subjects switch their auditory spatial attention.},
	urldate = {2024-06-03},
	journal = {NeuroImage},
	author = {Larson, Eric and Lee, Adrian K. C.},
	month = jan,
	year = {2013},
	keywords = {Auditory attention, Frontal eye fields, Magnetoencephalography, Temporoparietal junction},
	pages = {365--370},
	file = {Accepted Version:/Users/larsoner/Zotero/storage/TT9X5VZJ/Larson and Lee - 2013 - The cortical dynamics underlying effective switchi.pdf:application/pdf;ScienceDirect Snapshot:/Users/larsoner/Zotero/storage/P2RR5H5C/S1053811912009007.html:text/html},
}

@article{lee_auditory_2012,
	title = {Auditory selective attention reveals preparatory activity in different cortical regions for selection based on source location and source pitch},
	volume = {6},
	issn = {1662-453X},
	doi = {10.3389/fnins.2012.00190},
	abstract = {In order to extract information in a rich environment, we focus on different features that allow us to direct attention to whatever source is of interest. The cortical network deployed during spatial attention, especially in vision, is well characterized. For example, visuospatial attention engages a frontoparietal network including the frontal eye fields (FEFs), which modulate activity in visual sensory areas to enhance the representation of an attended visual object. However, relatively little is known about the neural circuitry controlling attention directed to non-spatial features, or to auditory objects or features (either spatial or non-spatial). Here, using combined magnetoencephalography (MEG) and anatomical information obtained from MRI, we contrasted cortical activity when observers attended to different auditory features given the same acoustic mixture of two simultaneous spoken digits. Leveraging the fine temporal resolution of MEG, we establish that activity in left FEF is enhanced both prior to and throughout the auditory stimulus when listeners direct auditory attention to target location compared to when they focus on target pitch. In contrast, activity in the left posterior superior temporal sulcus (STS), a region previously associated with auditory pitch categorization, is greater when listeners direct attention to target pitch rather than target location. This differential enhancement is only significant after observers are instructed which cue to attend, but before the acoustic stimuli begin. We therefore argue that left FEF participates more strongly in directing auditory spatial attention, while the left STS aids auditory object selection based on the non-spatial acoustic feature of pitch.},
	language = {eng},
	journal = {Frontiers in Neuroscience},
	author = {Lee, Adrian K. C. and Rajaram, Siddharth and Xia, Jing and Bharadwaj, Hari and Larson, Eric and Hämäläinen, Matti S. and Shinn-Cunningham, Barbara G.},
	year = {2012},
	pmid = {23335874},
	pmcid = {PMC3538445},
	keywords = {auditory attention, auditory spatial processing, frontal eye fields, magnetoencephalography, pitch processing, superior temporal sulcus, Superior temporal sulcus},
	pages = {190},
	file = {Full Text:/Users/larsoner/Zotero/storage/NMAZVB7Z/Lee et al. - 2012 - Auditory selective attention reveals preparatory a.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/MV5GDW5U/Lee et al. - 2013 - Auditory selective attention reveals preparatory a.pdf:application/pdf},
}

@article{wronkiewicz_leveraging_2015,
	title = {Leveraging anatomical information to improve transfer learning in brain-computer interfaces},
	volume = {12},
	issn = {1741-2552},
	doi = {10.1088/1741-2560/12/4/046027},
	abstract = {OBJECTIVE: Brain-computer interfaces (BCIs) represent a technology with the potential to rehabilitate a range of traumatic and degenerative nervous system conditions but require a time-consuming training process to calibrate. An area of BCI research known as transfer learning is aimed at accelerating training by recycling previously recorded training data across sessions or subjects. Training data, however, is typically transferred from one electrode configuration to another without taking individual head anatomy or electrode positioning into account, which may underutilize the recycled data.
APPROACH: We explore transfer learning with the use of source imaging, which estimates neural activity in the cortex. Transferring estimates of cortical activity, in contrast to scalp recordings, provides a way to compensate for variability in electrode positioning and head morphologies across subjects and sessions.
MAIN RESULTS: Based on simulated and measured electroencephalography activity, we trained a classifier using data transferred exclusively from other subjects and achieved accuracies that were comparable to or surpassed a benchmark classifier (representative of a real-world BCI). Our results indicate that classification improvements depend on the number of trials transferred and the cortical region of interest.
SIGNIFICANCE: These findings suggest that cortical source-based transfer learning is a principled method to transfer data that improves BCI classification performance and provides a path to reduce BCI calibration time.},
	language = {eng},
	number = {4},
	journal = {Journal of Neural Engineering},
	author = {Wronkiewicz, Mark and Larson, Eric and Lee, Adrian K. C.},
	month = aug,
	year = {2015},
	pmid = {26169961},
	pmcid = {PMC4527978},
	keywords = {Algorithms, Brain Mapping, Brain-Computer Interfaces, Cerebral Cortex, Computer Simulation, Electroencephalography, Humans, Information Storage and Retrieval, Machine Learning, Models, Anatomic, Models, Neurological, Pattern Recognition, Automated},
	pages = {046027},
	file = {Accepted Version:/Users/larsoner/Zotero/storage/DPR2J5IX/Wronkiewicz et al. - 2015 - Leveraging anatomical information to improve trans.pdf:application/pdf;IOP Full Text PDF:/Users/larsoner/Zotero/storage/JNX8PNR5/Wronkiewicz et al. - 2015 - Leveraging anatomical information to improve trans.pdf:application/pdf},
}

@article{gramfort_meg_2013,
	title = {{MEG} and {EEG} data analysis with {MNE}-{Python}},
	volume = {7},
	issn = {1662-4548},
	doi = {10.3389/fnins.2013.00267},
	abstract = {Magnetoencephalography and electroencephalography (M/EEG) measure the weak electromagnetic signals generated by neuronal activity in the brain. Using these signals to characterize and locate neural activation in the brain is a challenge that requires expertise in physics, signal processing, statistics, and numerical methods. As part of the MNE software suite, MNE-Python is an open-source software package that addresses this challenge by providing state-of-the-art algorithms implemented in Python that cover multiple methods of data preprocessing, source localization, statistical analysis, and estimation of functional connectivity between distributed brain regions. All algorithms and utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysis pipelines by writing Python scripts. Moreover, MNE-Python is tightly integrated with the core Python libraries for scientific comptutation (NumPy, SciPy) and visualization (matplotlib and Mayavi), as well as the greater neuroimaging ecosystem in Python via the Nibabel package. The code is provided under the new BSD license allowing code reuse, even in commercial products. Although MNE-Python has only been under heavy development for a couple of years, it has rapidly evolved with expanded analysis capabilities and pedagogical tutorials because multiple labs have collaborated during code development to help share best practices. MNE-Python also gives easy access to preprocessed datasets, helping users to get started quickly and facilitating reproducibility of methods by other researchers. Full documentation, including dozens of examples, is available at http://martinos.org/mne.},
	language = {eng},
	journal = {Frontiers in Neuroscience},
	author = {Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A. and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and Hämäläinen, Matti},
	month = dec,
	year = {2013},
	pmid = {24431986},
	pmcid = {PMC3872725},
	keywords = {electroencephalography (EEG), Electroencephalography (EEG), magnetoencephalography (MEG), Magnetoencephalography (MEG), neuroimaging, Neuroimaging, open-source, python, software, Software},
	pages = {267},
	file = {Full Text:/Users/larsoner/Zotero/storage/F4LR3YAB/Gramfort et al. - 2013 - MEG and EEG data analysis with MNE-Python.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/8MKE854E/Gramfort et al. - 2013 - MEG and EEG data analysis with MNE-Python.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/2IY27UBJ/Gramfort et al. - 2013 - MEG and EEG data analysis with MNE-Python.pdf:application/pdf},
}

@article{larson_influence_2013,
	title = {Influence of preparation time and pitch separation in switching of auditory attention between streams},
	volume = {134},
	issn = {0001-4966},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3724725/},
	doi = {10.1121/1.4812439},
	abstract = {The ability to consciously switch attention between speakers of interest is necessary for communication in many environments, especially when multiple talkers speak simultaneously. Segregating sounds of interest from the background, which is necessary for selective attention, depends on stimulus acoustics such as differences in spectrotemporal properties of the target and masker. However, the relationship between top-down attention control and bottom-up stimulus segregation is not well understood. Here, two experiments were conducted to examine the time necessary for listeners to switch auditory attention, and how the ability to switch attention relates to the pitch separation cue available for bottom-up stream segregation.},
	number = {2},
	urldate = {2024-06-03},
	journal = {The Journal of the Acoustical Society of America},
	author = {Larson, Eric and Lee, Adrian K. C.},
	month = aug,
	year = {2013},
	pmid = {23927220},
	pmcid = {PMC3724725},
	keywords = {Hearing},
	pages = {EL165--EL171},
	file = {Full Text:/Users/larsoner/Zotero/storage/5969A8MQ/Larson and Lee - 2013 - Influence of preparation time and pitch separation.pdf:application/pdf;JAS0EL165.pdf:/Users/larsoner/Zotero/storage/DFPZHVUE/JAS0EL165.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/NF7UNZBC/pEL165_s1.html:text/html},
}

@article{clarke_infant_2022,
	title = {Infant brain imaging using magnetoencephalography: {Challenges}, solutions, and best practices},
	volume = {43},
	issn = {1097-0193},
	shorttitle = {Infant brain imaging using magnetoencephalography},
	doi = {10.1002/hbm.25871},
	abstract = {The excellent temporal resolution and advanced spatial resolution of magnetoencephalography (MEG) makes it an excellent tool to study the neural dynamics underlying cognitive processes in the developing brain. Nonetheless, a number of challenges exist when using MEG to image infant populations. There is a persistent belief that collecting MEG data with infants presents a number of limitations and challenges that are difficult to overcome. Due to this notion, many researchers either avoid conducting infant MEG research or believe that, in order to collect high-quality data, they must impose limiting restrictions on the infant or the experimental paradigm. In this article, we discuss the various challenges unique to imaging awake infants and young children with MEG, and share general best-practice guidelines and recommendations for data collection, acquisition, preprocessing, and analysis. The current article is focused on methodology that allows investigators to test the sensory, perceptual, and cognitive capacities of awake and moving infants. We believe that such methodology opens the pathway for using MEG to provide mechanistic explanations for the complex behavior observed in awake, sentient, and dynamically interacting infants, thus addressing core topics in developmental cognitive neuroscience.},
	language = {eng},
	number = {12},
	journal = {Human Brain Mapping},
	author = {Clarke, Maggie D. and Bosseler, Alexis N. and Mizrahi, Julia C. and Peterson, Erica R. and Larson, Eric and Meltzoff, Andrew N. and Kuhl, Patricia K. and Taulu, Samu},
	month = aug,
	year = {2022},
	pmid = {35429095},
	pmcid = {PMC9294291},
	keywords = {analysis, Brain, Brain Mapping, Child, Child, Preschool, guidelines, Head, Humans, infant, Infant, magnetoencephalography, Magnetoencephalography, MEG, processing, recommendations},
	pages = {3609--3619},
	file = {Full Text:/Users/larsoner/Zotero/storage/YFVF95FC/Clarke et al. - 2022 - Infant brain imaging using magnetoencephalography.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/7G3GUWWB/Clarke et al. - Infant brain imaging using magnetoencephalography.pdf:application/pdf;Snapshot:/Users/larsoner/Zotero/storage/H9W3ACCK/hbm.html:text/html},
}

@article{lee_effects_2018,
	title = {Effects of hearing loss on maintaining and switching attention},
	volume = {104},
	issn = {1610-1928},
	doi = {10.3813/aaa.919224},
	abstract = {The ability to intentionally control attention based on task goals and stimulus properties is critical to communication in many environments. However, when a person has a damaged auditory system, such as with hearing loss, perceptual organization may also be impaired, making it more difficult to direct attention to different auditory objects in the environment. Here we examined the behavioral cost associated with maintaining and switching attention in people with hearing loss compared to the normal hearing population, and found a cost associated with attending to a target stream in a multi-talker environment that cannot solely be attributed to audibility issues.},
	language = {eng},
	number = {5},
	journal = {Acta acustica united with acustica: the journal of the European Acoustics Association (EEIG)},
	author = {Lee, Adrian Kc and Larson, Eric and Miller, Christi W.},
	year = {2018},
	pmid = {32863813},
	pmcid = {PMC7454162},
	pages = {787--791},
	file = {Full Text:/Users/larsoner/Zotero/storage/NGCYS2TU/Lee et al. - 2018 - Effects of hearing loss on maintaining and switchi.pdf:application/pdf;PubMed Central Full Text PDF:/Users/larsoner/Zotero/storage/9M24XWDP/Lee et al. - 2018 - Effects of hearing loss on maintaining and switchi.pdf:application/pdf},
}

@article{clarke_improving_2022,
	title = {Improving {Localization} {Accuracy} of {Neural} {Sources} by {Pre}-processing: {Demonstration} {With} {Infant} {MEG} {Data}},
	volume = {13},
	issn = {1664-2295},
	shorttitle = {Improving {Localization} {Accuracy} of {Neural} {Sources} by {Pre}-processing},
	doi = {10.3389/fneur.2022.827529},
	abstract = {We discuss specific challenges and solutions in infant MEG, which is one of the most technically challenging areas of MEG studies. Our results can be generalized to a variety of challenging scenarios for MEG data acquisition, including clinical settings. We cover a wide range of steps in pre-processing, including movement compensation, suppression of magnetic interference from sources inside and outside the magnetically shielded room, suppression of specific physiological artifact components such as cardiac artifacts. In the assessment of the outcome of the pre-processing algorithms, we focus on comparing signal representation before and after pre-processing and discuss the importance of the different components of the main processing steps. We discuss the importance of taking the noise covariance structure into account in inverse modeling and present the proper treatment of the noise covariance matrix to accurately reflect the processing that was applied to the data. Using example cases, we investigate the level of source localization error before and after processing. One of our main findings is that statistical metrics of source reconstruction may erroneously indicate that the results are reliable even in cases where the data are severely distorted by head movements. As a consequence, we stress the importance of proper signal processing in infant MEG.},
	language = {eng},
	journal = {Frontiers in Neurology},
	author = {Clarke, Maggie D. and Larson, Eric and Peterson, Erica R. and McCloy, Daniel R. and Bosseler, Alexis N. and Taulu, Samu},
	year = {2022},
	pmid = {35401424},
	pmcid = {PMC8983818},
	keywords = {artifact, brain, infant, magnetoencephalography (MEG), movement compensation, signal processing, signal space projection, signal space separation},
	pages = {827529},
	file = {Full Text:/Users/larsoner/Zotero/storage/4GGY5FN6/Clarke et al. - 2022 - Improving Localization Accuracy of Neural Sources .pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/33AD53VW/Clarke et al. - 2022 - Improving Localization Accuracy of Neural Sources .pdf:application/pdf},
}

@article{jas_reproducible_2018,
	title = {A {Reproducible} {MEG}/{EEG} {Group} {Study} {With} the {MNE} {Software}: {Recommendations}, {Quality} {Assessments}, and {Good} {Practices}},
	volume = {12},
	issn = {1662-4548},
	shorttitle = {A {Reproducible} {MEG}/{EEG} {Group} {Study} {With} the {MNE} {Software}},
	doi = {10.3389/fnins.2018.00530},
	abstract = {Cognitive neuroscience questions are commonly tested with experiments that involve a cohort of subjects. The cohort can consist of a handful of subjects for small studies to hundreds or thousands of subjects in open datasets. While there exist various online resources to get started with the analysis of magnetoencephalography (MEG) or electroencephalography (EEG) data, such educational materials are usually restricted to the analysis of a single subject. This is in part because data from larger group studies are harder to share, but also analyses of such data often require subject-specific decisions which are hard to document. This work presents the results obtained by the reanalysis of an open dataset from Wakeman and Henson (2015) using the MNE software package. The analysis covers preprocessing steps, quality assurance steps, sensor space analysis of evoked responses, source localization, and statistics in both sensor and source space. Results with possible alternative strategies are presented and discussed at different stages such as the use of high-pass filtering versus baseline correction, tSSS vs. SSS, the use of a minimum norm inverse vs. LCMV beamformer, and the use of univariate or multivariate statistics. This aims to provide a comparative study of different stages of M/EEG analysis pipeline on the same dataset, with open access to all of the scripts necessary to reproduce this analysis.},
	language = {eng},
	journal = {Frontiers in Neuroscience},
	author = {Jas, Mainak and Larson, Eric and Engemann, Denis A. and Leppäkangas, Jaakko and Taulu, Samu and Hämäläinen, Matti and Gramfort, Alexandre},
	year = {2018},
	pmid = {30127712},
	pmcid = {PMC6088222},
	keywords = {electroencephalography (EEG), magnetoencephalography (MEG), neuroimaging, open-source, Python, software},
	pages = {530},
	file = {Full Text:/Users/larsoner/Zotero/storage/RSYBXP5C/Jas et al. - 2018 - A Reproducible MEGEEG Group Study With the MNE So.pdf:application/pdf},
}

@article{larson_potential_2014,
	title = {Potential {Use} of {MEG} to {Understand} {Abnormalities} in {Auditory} {Function} in {Clinical} {Populations}},
	volume = {8},
	issn = {1662-5161},
	doi = {10.3389/fnhum.2014.00151},
	abstract = {Magnetoencephalography (MEG) provides a direct, non-invasive view of neural activity with millisecond temporal precision. Recent developments in MEG analysis allow for improved source localization and mapping of connectivity between brain regions, expanding the possibilities for using MEG as a diagnostic tool. In this paper, we first describe inverse imaging methods (e.g., minimum-norm estimation) and functional connectivity measures, and how they can provide insights into cortical processing. We then offer a perspective on how these techniques could be used to understand and evaluate auditory pathologies that often manifest during development. Here we focus specifically on how MEG inverse imaging, by providing anatomically based interpretation of neural activity, may allow us to test which aspects of cortical processing play a role in (central) auditory processing disorder [(C)APD]. Appropriately combining auditory paradigms with MEG analysis could eventually prove useful for a hypothesis-driven understanding and diagnosis of (C)APD or other disorders, as well as the evaluation of the effectiveness of intervention strategies.},
	language = {eng},
	journal = {Frontiers in Human Neuroscience},
	author = {Larson, Eric and Lee, Adrian K. C.},
	year = {2014},
	pmid = {24659963},
	pmcid = {PMC3952190},
	keywords = {audition, Audition, central auditory processing disorder, clinical practice, magnetoencephalography, minimum-norm estimates},
	pages = {151},
	file = {Full Text:/Users/larsoner/Zotero/storage/UWSLGFQW/Larson and Lee - 2014 - Potential Use of MEG to Understand Abnormalities i.pdf:application/pdf;Full Text PDF:/Users/larsoner/Zotero/storage/GHVCBIU9/Larson and Lee - 2014 - Potential use of MEG to understand abnormalities i.pdf:application/pdf},
}

@article{larson_audio-visual_2012,
	title = {Audio-visual feedback for electromyographic control of vowel synthesis},
	volume = {2012},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2012.6346745},
	abstract = {We describe the design and testing of a human machine interface to use surface electromyography (sEMG) collected from a covert location in response audio-visual feedback. Using sEMG collected from the Auricularis Posterior muscle, N=5 healthy participants participated in 6 sessions over multiple days to learn to transition from visual and vowel synthesis feedback to vowel synthesis feedback alone. Results indicate that individuals are able to learn sEMG control of vowel synthesis using auditory feedback alone with an average of 67\% accuracy and that this skill can also generalize to new vowel targets. Control of vowel synthesis using covertly-recorded sEMG is a promising step toward more reliable mobile human machine interfaces for communication.},
	language = {eng},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference},
	author = {Larson, Eric and Terry, Howard P. and Stepp, Cara E.},
	year = {2012},
	pmid = {23366706},
	pmcid = {PMC10184648},
	keywords = {Adult, Biofeedback, Psychology, Electromyography, Female, Humans, Male, Speech, Young Adult},
	pages = {3600--3603},
	file = {Accepted Version:/Users/larsoner/Zotero/storage/VD8K9ZGQ/Larson et al. - 2012 - Audio-visual feedback for electromyographic contro.pdf:application/pdf},
}

@article{hands_role_2013,
	title = {The role of augmentative visual training in auditory human-machine-interface performance},
	volume = {2013},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2013.6610123},
	abstract = {The purpose of this study was to evaluate the effect of augmentative visual feedback training on performance using auditory feedback alone for human-machine interface (HMI) control. Sixteen healthy participants used bilateral facial surface electromyography to achieve two-dimensional control to reach vowel targets. Eight participants trained with combined visual and auditory feedback, while eight participants trained with real-time auditory feedback only. Each subject participated in four sessions over three days; three sessions with their designated feedback modality (auditory only or auditory with supplementary visual) and a fourth session on the third day using novel vowel targets to test generalization of auditory-motor learning. Analyses of variance performed on the percentage of total targets reached demonstrated a main effect of group and the interaction of group and session. Individuals provided with augmentative visual feedback during training outperformed individuals using auditory feedback alone in initial training sessions. However, training with augmentative visual feedback had no effect on individuals' training and generalization performance using auditory feedback alone after three days of training.},
	language = {eng},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference},
	author = {Hands, Gabrielle L. and Larson, Eric and Stepp, Cara E.},
	year = {2013},
	pmid = {24110310},
	keywords = {Acoustic Stimulation, Electrodes, Electromyography, Feedback, Sensory, Female, Humans, Male, User-Computer Interface, Young Adult},
	pages = {2804--2807},
}

@article{wronkiewicz_towards_2013,
	title = {Towards a next-generation hearing aid through brain state classification and modeling},
	volume = {2013},
	issn = {2694-0604},
	doi = {10.1109/EMBC.2013.6610124},
	abstract = {Traditional brain-state classifications are primarily based on two well-known neural biomarkers: P300 and motor imagery / event-related frequency modulation. Currently, many brain-computer interface (BCI) systems have successfully helped patients with severe neuromuscular disabilities to regain independence. In order to translate this neural engineering success to hearing aid applications, we must be able to capture brain waves across the population reliably in cortical regions that have not previously been incorporated in these systems before, for example, dorsolateral prefrontal cortex (DLPFC) and right temporoparietal junction. Here, we present a brain-state classification framework that incorporates individual anatomical information and accounts for potential anatomical and functional differences across subjects by applying appropriate cortical weighting functions prior to the classification stage. Using an inverse imaging approach, use simulated EEG data to show that our method can outperform the traditional brain-state classification approach that trains only on individual subject's data without considering data available at a population level.},
	language = {eng},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference},
	author = {Wronkiewicz, Mark and Larson, Eric and Lee, Adrian K. C.},
	year = {2013},
	pmid = {24110311},
	pmcid = {PMC5930482},
	keywords = {Brain, Brain Mapping, Brain-Computer Interfaces, Computer Simulation, Hearing Aids, Humans, Models, Biological, Prefrontal Cortex},
	pages = {2808--2811},
	file = {Accepted Version:/Users/larsoner/Zotero/storage/QDTNRLU3/Wronkiewicz et al. - 2013 - Towards a next-generation hearing aid through brai.pdf:application/pdf},
}
